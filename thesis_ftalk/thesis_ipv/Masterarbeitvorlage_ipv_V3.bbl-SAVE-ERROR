% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{he_deep_2016}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
        {{hash=5e72bc22dbcf0984c6d113d280e36990}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiangyu},
           giveni={X\bibinitperiod}}}%
        {{hash=bb295293acacd54387339079ebbe4ead}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Shaoqing},
           giveni={S\bibinitperiod}}}%
        {{hash=f85751488058842b5777c7b4074077b5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Las Vegas, NV, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{fullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{bibnamehash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{authorbibnamehash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \strng{authornamehash}{6edb98fe38401d2fe4a026f5ce6e8451}
      \strng{authorfullhash}{42c4b52dc3a62cebabbc11c73e1afb53}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{isbn}{978-1-4673-8851-1}
      \field{month}{6}
      \field{title}{Deep {Residual} {Learning} for {Image} {Recognition}}
      \field{year}{2016}
      \field{pages}{770\bibrangedash 778}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/CVPR.2016.90
      \endverb
      \verb{file}
      \verb Accepted Version:/Users/mengze/Zotero/storage/53RUHC6D/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7780459/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7780459/
      \endverb
    \endentry
    \entry{huang_densely_2018}{misc}{}
      \name{author}{4}{}{%
        {{hash=0d12f90a1d1945cb1b98f583c9dc9572}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Gao},
           giveni={G\bibinitperiod}}}%
        {{hash=f7eda249dc15ce9f452344ec95bbcc67}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Zhuang},
           giveni={Z\bibinitperiod}}}%
        {{hash=47fbe2837893a84fb516e9e85ba7aa36}{%
           family={Maaten},
           familyi={M\bibinitperiod},
           given={Laurens},
           giveni={L\bibinitperiod},
           prefix={van\bibnamedelima der},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=68a0238356fbd88b34be8886f25938a7}{%
           family={Weinberger},
           familyi={W\bibinitperiod},
           given={Kilian\bibnamedelima Q.},
           giveni={K\bibinitperiod\bibinitdelim Q\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{3dcda21c08021918fcbe6ecf2e003538}
      \strng{fullhash}{bdb4a5391f81b99dc554fecb00ecee8f}
      \strng{bibnamehash}{bdb4a5391f81b99dc554fecb00ecee8f}
      \strng{authorbibnamehash}{bdb4a5391f81b99dc554fecb00ecee8f}
      \strng{authornamehash}{3dcda21c08021918fcbe6ecf2e003538}
      \strng{authorfullhash}{bdb4a5391f81b99dc554fecb00ecee8f}
      \field{extraname}{1}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .}
      \field{month}{1}
      \field{note}{arXiv:1608.06993 [cs]}
      \field{title}{Densely {Connected} {Convolutional} {Networks}}
      \field{year}{2018}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/VLYE62D4/Huang et al. - 2018 - Densely Connected Convolutional Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/KXBSBP5X/1608.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1608.06993
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1608.06993
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{dosovitskiy_image_2021}{misc}{}
      \name{author}{12}{}{%
        {{hash=72308762399d6ab62bbd9391c64c7bfd}{%
           family={Dosovitskiy},
           familyi={D\bibinitperiod},
           given={Alexey},
           giveni={A\bibinitperiod}}}%
        {{hash=836254958eac09b30d45dd67a75ce4fa}{%
           family={Beyer},
           familyi={B\bibinitperiod},
           given={Lucas},
           giveni={L\bibinitperiod}}}%
        {{hash=6807e3c00242c6bf6a3179905040471b}{%
           family={Kolesnikov},
           familyi={K\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=b398fca6879fde89a032b8e7de2f26b5}{%
           family={Weissenborn},
           familyi={W\bibinitperiod},
           given={Dirk},
           giveni={D\bibinitperiod}}}%
        {{hash=00b950307c7d096765bb6df00c7c5c3a}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Xiaohua},
           giveni={X\bibinitperiod}}}%
        {{hash=1a47640139e63b9b5969c969dfe95def}{%
           family={Unterthiner},
           familyi={U\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=965baf6fa5686a42b1564330c5e11f2f}{%
           family={Dehghani},
           familyi={D\bibinitperiod},
           given={Mostafa},
           giveni={M\bibinitperiod}}}%
        {{hash=06829adce8713f0ace444279dcd7328f}{%
           family={Minderer},
           familyi={M\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=c95269b4a2e23e1e526be521c7ec6ad4}{%
           family={Heigold},
           familyi={H\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod}}}%
        {{hash=450963f966620925cb8fecd32f7a6ee1}{%
           family={Gelly},
           familyi={G\bibinitperiod},
           given={Sylvain},
           giveni={S\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=493a532418540859dca92cf3b579de2a}{%
           family={Houlsby},
           familyi={H\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{d96316bc7578db680aba71d4226354c8}
      \strng{fullhash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \strng{bibnamehash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \strng{authorbibnamehash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \strng{authornamehash}{d96316bc7578db680aba71d4226354c8}
      \strng{authorfullhash}{b8c06eaeb698f61fc96ff3e5570552ec}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.}
      \field{month}{6}
      \field{note}{arXiv:2010.11929 [cs]}
      \field{shorttitle}{An {Image} is {Worth} 16x16 {Words}}
      \field{title}{An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}}
      \field{year}{2021}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/MQ5BGUSJ/Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/SGKWQP5D/2010.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2010.11929
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2010.11929
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{arnab_vivit_2021}{misc}{}
      \name{author}{6}{}{%
        {{hash=a4cc19a9b2b2a4333ac5365d6f7c40a5}{%
           family={Arnab},
           familyi={A\bibinitperiod},
           given={Anurag},
           giveni={A\bibinitperiod}}}%
        {{hash=965baf6fa5686a42b1564330c5e11f2f}{%
           family={Dehghani},
           familyi={D\bibinitperiod},
           given={Mostafa},
           giveni={M\bibinitperiod}}}%
        {{hash=c95269b4a2e23e1e526be521c7ec6ad4}{%
           family={Heigold},
           familyi={H\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod}}}%
        {{hash=7437556e576c6f4e2ade58a9aa980ec5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Chen},
           giveni={C\bibinitperiod}}}%
        {{hash=c4d5818a6677e2935af06184ad55c72a}{%
           family={Lučić},
           familyi={L\bibinitperiod},
           given={Mario},
           giveni={M\bibinitperiod}}}%
        {{hash=58e4a9845eac42a4b0e5205cf0970fc0}{%
           family={Schmid},
           familyi={S\bibinitperiod},
           given={Cordelia},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{9c773be7d421a5c671208f6e3e9b9ac9}
      \strng{fullhash}{3f9cfecd2391ea89adb39d3c8565e47d}
      \strng{bibnamehash}{3f9cfecd2391ea89adb39d3c8565e47d}
      \strng{authorbibnamehash}{3f9cfecd2391ea89adb39d3c8565e47d}
      \strng{authornamehash}{9c773be7d421a5c671208f6e3e9b9ac9}
      \strng{authorfullhash}{3f9cfecd2391ea89adb39d3c8565e47d}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We present pure-transformer based models for video classification, drawing upon the recent success of such models in image classification. Our model extracts spatio-temporal tokens from the input video, which are then encoded by a series of transformer layers. In order to handle the long sequences of tokens encountered in video, we propose several, efficient variants of our model which factorise the spatial- and temporal-dimensions of the input. Although transformer-based models are known to only be effective when large training datasets are available, we show how we can effectively regularise the model during training and leverage pretrained image models to be able to train on comparatively small datasets. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple video classification benchmarks including Kinetics 400 and 600, Epic Kitchens, Something-Something v2 and Moments in Time, outperforming prior methods based on deep 3D convolutional networks. To facilitate further research, we release code at https://github.com/google-research/scenic/tree/main/scenic/projects/vivit}
      \field{month}{11}
      \field{note}{arXiv:2103.15691 [cs]}
      \field{shorttitle}{{ViViT}}
      \field{title}{{ViViT}: {A} {Video} {Vision} {Transformer}}
      \field{year}{2021}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/YHUSN4MZ/Arnab et al. - 2021 - ViViT A Video Vision Transformer.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/N5TECX65/2103.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2103.15691
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2103.15691
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{bertasius_is_2021}{misc}{}
      \name{author}{3}{}{%
        {{hash=8542d85068f9aceb7d66c195741bacae}{%
           family={Bertasius},
           familyi={B\bibinitperiod},
           given={Gedas},
           giveni={G\bibinitperiod}}}%
        {{hash=29fa9ac4da972e0174f94c469eae902a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Heng},
           giveni={H\bibinitperiod}}}%
        {{hash=7174975989c609900098ef361edc9286}{%
           family={Torresani},
           familyi={T\bibinitperiod},
           given={Lorenzo},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{42cc03b3fbc5de8a128a4c9b4e5aa1ef}
      \strng{fullhash}{4b7eef2dc90cc483b89dfaf08a6a0c8b}
      \strng{bibnamehash}{4b7eef2dc90cc483b89dfaf08a6a0c8b}
      \strng{authorbibnamehash}{4b7eef2dc90cc483b89dfaf08a6a0c8b}
      \strng{authornamehash}{42cc03b3fbc5de8a128a4c9b4e5aa1ef}
      \strng{authorfullhash}{4b7eef2dc90cc483b89dfaf08a6a0c8b}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named "TimeSformer," adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of frame-level patches. Our experimental study compares different self-attention schemes and suggests that "divided attention," where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/facebookresearch/TimeSformer.}
      \field{month}{6}
      \field{note}{arXiv:2102.05095 [cs]}
      \field{title}{Is {Space}-{Time} {Attention} {All} {You} {Need} for {Video} {Understanding}?}
      \field{year}{2021}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/23INWZ9U/Bertasius et al. - 2021 - Is Space-Time Attention All You Need for Video Und.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/TEBFV9MU/2102.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2102.05095
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2102.05095
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{liu2021swin}{misc}{}
      \name{author}{8}{}{%
        {{hash=19aabf2deb737584450693431af51cc3}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Ze},
           giveni={Z\bibinitperiod}}}%
        {{hash=3c6a54dc09fe06657a89a749043b2133}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Yutong},
           giveni={Y\bibinitperiod}}}%
        {{hash=5fde2ec473a5900f24f02ea9a11359ed}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Yue},
           giveni={Y\bibinitperiod}}}%
        {{hash=f19295c2c8bee05248e05cdbfd48b247}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Han},
           giveni={H\bibinitperiod}}}%
        {{hash=1d41b11667193fc2d6d720337c963955}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Yixuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=fcdb4c7704baa79893b29d652aecc77f}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=eb40fa909f02eebf8c76aedeab111038}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod}}}%
        {{hash=5635e5718e86c9052afcaa71d2097959}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Baining},
           giveni={B\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{009ce81df9957b336af5b72e75724e0c}
      \strng{fullhash}{4573863b62d52acb9c29e180e6f47f26}
      \strng{bibnamehash}{4573863b62d52acb9c29e180e6f47f26}
      \strng{authorbibnamehash}{4573863b62d52acb9c29e180e6f47f26}
      \strng{authornamehash}{009ce81df9957b336af5b72e75724e0c}
      \strng{authorfullhash}{4573863b62d52acb9c29e180e6f47f26}
      \field{extraname}{1}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{month}{8}
      \field{note}{arXiv:2103.14030 [cs]}
      \field{shorttitle}{Swin {Transformer}}
      \field{title}{Swin {Transformer}: {Hierarchical} {Vision} {Transformer} using {Shifted} {Windows}}
      \field{urlday}{11}
      \field{urlmonth}{11}
      \field{urlyear}{2023}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/26GU7KZH/Liu et al. - 2021 - Swin Transformer Hierarchical Vision Transformer .pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/HMNHE4TC/2103.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2103.14030
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2103.14030
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{liu_video_2021}{misc}{}
      \name{author}{7}{}{%
        {{hash=19aabf2deb737584450693431af51cc3}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Ze},
           giveni={Z\bibinitperiod}}}%
        {{hash=9dbce503d9c11f7f604872d4f7f7451a}{%
           family={Ning},
           familyi={N\bibinitperiod},
           given={Jia},
           giveni={J\bibinitperiod}}}%
        {{hash=5fde2ec473a5900f24f02ea9a11359ed}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Yue},
           giveni={Y\bibinitperiod}}}%
        {{hash=1d41b11667193fc2d6d720337c963955}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Yixuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=fcdb4c7704baa79893b29d652aecc77f}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=eb40fa909f02eebf8c76aedeab111038}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod}}}%
        {{hash=f19295c2c8bee05248e05cdbfd48b247}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Han},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{009ce81df9957b336af5b72e75724e0c}
      \strng{fullhash}{80e5927e2b7d07ce889842ba604f016e}
      \strng{bibnamehash}{80e5927e2b7d07ce889842ba604f016e}
      \strng{authorbibnamehash}{80e5927e2b7d07ce889842ba604f016e}
      \strng{authornamehash}{009ce81df9957b336af5b72e75724e0c}
      \strng{authorfullhash}{80e5927e2b7d07ce889842ba604f016e}
      \field{extraname}{2}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The vision community is witnessing a modeling shift from CNNs to Transformers, where pure Transformer architectures have attained top accuracy on the major video recognition benchmarks. These video models are all built on Transformer layers that globally connect patches across the spatial and temporal dimensions. In this paper, we instead advocate an inductive bias of locality in video Transformers, which leads to a better speed-accuracy trade-off compared to previous approaches which compute self-attention globally even with spatial-temporal factorization. The locality of the proposed video architecture is realized by adapting the Swin Transformer designed for the image domain, while continuing to leverage the power of pre-trained image models. Our approach achieves state-of-the-art accuracy on a broad range of video recognition benchmarks, including on action recognition (84.9 top-1 accuracy on Kinetics-400 and 86.1 top-1 accuracy on Kinetics-600 with {\textasciitilde}20x less pre-training data and {\textasciitilde}3x smaller model size) and temporal modeling (69.6 top-1 accuracy on Something-Something v2). The code and models will be made publicly available at https://github.com/SwinTransformer/Video-Swin-Transformer.}
      \field{month}{6}
      \field{note}{arXiv:2106.13230 [cs]}
      \field{title}{Video {Swin} {Transformer}}
      \field{year}{2021}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/2GNTS8CG/Liu et al. - 2021 - Video Swin Transformer.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/BVPHYLTK/2106.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2106.13230
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2106.13230
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
    \endentry
    \entry{shan_understanding_2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=cd1f0255cea7387ec0353bd315923481}{%
           family={Shan},
           familyi={S\bibinitperiod},
           given={Dandan},
           giveni={D\bibinitperiod}}}%
        {{hash=779ae0944b6a7feaaa74ec0146a39d7a}{%
           family={Geng},
           familyi={G\bibinitperiod},
           given={Jiaqi},
           giveni={J\bibinitperiod}}}%
        {{hash=e056e82e5b54418d5ec9fb96f118a16c}{%
           family={Shu},
           familyi={S\bibinitperiod},
           given={Michelle},
           giveni={M\bibinitperiod}}}%
        {{hash=7d94f96daf3f8453a9a91042a74184d9}{%
           family={Fouhey},
           familyi={F\bibinitperiod},
           given={David\bibnamedelima F.},
           giveni={D\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Seattle, WA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{16635362586086111fee2550d20f4115}
      \strng{fullhash}{ce666c92f6a0545b34d09a148ed6abf6}
      \strng{bibnamehash}{ce666c92f6a0545b34d09a148ed6abf6}
      \strng{authorbibnamehash}{ce666c92f6a0545b34d09a148ed6abf6}
      \strng{authornamehash}{16635362586086111fee2550d20f4115}
      \strng{authorfullhash}{ce666c92f6a0545b34d09a148ed6abf6}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{isbn}{978-1-72817-168-5}
      \field{month}{6}
      \field{title}{Understanding {Human} {Hands} in {Contact} at {Internet} {Scale}}
      \field{year}{2020}
      \field{pages}{9866\bibrangedash 9875}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/CVPR42600.2020.00989
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/mengze/Zotero/storage/5D3G97NL/Shan et al. - 2020 - Understanding Human Hands in Contact at Internet S.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9157473/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9157473/
      \endverb
    \endentry
    \entry{pan_egovit_2023}{misc}{}
      \name{author}{4}{}{%
        {{hash=30a1f932015629cd585290e52f1d27ab}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Chenbin},
           giveni={C\bibinitperiod}}}%
        {{hash=67820a734cead2ba7309f0f35ce90e1f}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhiqi},
           giveni={Z\bibinitperiod}}}%
        {{hash=9c3973ce1111be7cc1964bd7a1784b2b}{%
           family={Velipasalar},
           familyi={V\bibinitperiod},
           given={Senem},
           giveni={S\bibinitperiod}}}%
        {{hash=c7609922d2d0d41bda4e39b9bd864203}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{db7d278361fe1923e8e9f6923bbdae5e}
      \strng{fullhash}{5f94fb3bc80e7c6c3bf3b4e3a10bdada}
      \strng{bibnamehash}{5f94fb3bc80e7c6c3bf3b4e3a10bdada}
      \strng{authorbibnamehash}{5f94fb3bc80e7c6c3bf3b4e3a10bdada}
      \strng{authornamehash}{db7d278361fe1923e8e9f6923bbdae5e}
      \strng{authorfullhash}{5f94fb3bc80e7c6c3bf3b4e3a10bdada}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Capturing interaction of hands with objects is important to autonomously detect human actions from egocentric videos. In this work, we present a pyramid video transformer with a dynamic class token generator for egocentric action recognition. Different from previous video transformers, which use the same static embedding as the class token for diverse inputs, we propose a dynamic class token generator that produces a class token for each input video by analyzing the hand-object interaction and the related motion information. The dynamic class token can diffuse such information to the entire model by communicating with other informative tokens in the subsequent transformer layers. With the dynamic class token, dissimilarity between videos can be more prominent, which helps the model distinguish various inputs. In addition, traditional video transformers explore temporal features globally, which requires large amounts of computation. However, egocentric videos often have a large amount of background scene transition, which causes discontinuities across distant frames. In this case, blindly reducing the temporal sampling rate will risk losing crucial information. Hence, we also propose a pyramid architecture to hierarchically process the video from short-term high rate to long-term low rate. With the proposed architecture, we significantly reduce the computational cost as well as the memory requirement without sacrificing from the model performance. We perform comparisons with different baseline video transformers on the EPIC-KITCHENS-100 and EGTEA Gaze+ datasets. Both quantitative and qualitative results show that the proposed model can efficiently improve the performance for egocentric action recognition.}
      \field{month}{3}
      \field{note}{arXiv:2303.08920 [cs]}
      \field{shorttitle}{{EgoViT}}
      \field{title}{{EgoViT}: {Pyramid} {Video} {Transformer} for {Egocentric} {Action} {Recognition}}
      \field{year}{2023}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/2HMEFC85/Pan et al. - 2023 - EgoViT Pyramid Video Transformer for Egocentric A.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/LAYB74H2/2303.html:text/html;Full Text:/Users/mengze/Zotero/storage/DBYF6YLY/Pan et al. - 2023 - EgoViT Pyramid Video Transformer for Egocentric A.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2303.08920
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2303.08920
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{hayhoe_eye_2005}{article}{}
      \name{author}{2}{}{%
        {{hash=cfe81a69f9791c85ba21e7af7d9587d7}{%
           family={Hayhoe},
           familyi={H\bibinitperiod},
           given={Mary},
           giveni={M\bibinitperiod}}}%
        {{hash=0f02b00bf5d89f6d51044cf55cde445b}{%
           family={Ballard},
           familyi={B\bibinitperiod},
           given={Dana},
           giveni={D\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{9507cea63f5dc514fe3b341f21982d65}
      \strng{fullhash}{9507cea63f5dc514fe3b341f21982d65}
      \strng{bibnamehash}{9507cea63f5dc514fe3b341f21982d65}
      \strng{authorbibnamehash}{9507cea63f5dc514fe3b341f21982d65}
      \strng{authornamehash}{9507cea63f5dc514fe3b341f21982d65}
      \strng{authorfullhash}{9507cea63f5dc514fe3b341f21982d65}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{13646613}
      \field{journaltitle}{Trends in Cognitive Sciences}
      \field{month}{4}
      \field{number}{4}
      \field{title}{Eye movements in natural behavior}
      \field{volume}{9}
      \field{year}{2005}
      \field{pages}{188\bibrangedash 194}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1016/j.tics.2005.02.009
      \endverb
      \verb{file}
      \verb Hayhoe and Ballard - 2005 - Eye movements in natural behavior.pdf:/Users/mengze/Zotero/storage/S6IJRPY7/Hayhoe and Ballard - 2005 - Eye movements in natural behavior.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S1364661305000598
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S1364661305000598
      \endverb
    \endentry
    \entry{land_roles_1999}{article}{}
      \name{author}{3}{}{%
        {{hash=e376b3df2f7d8d02065ae5f928b41dcb}{%
           family={Land},
           familyi={L\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=d3573cdf6fe1732bfd2a8dc9d2d1fff9}{%
           family={Mennie},
           familyi={M\bibinitperiod},
           given={Neil},
           giveni={N\bibinitperiod}}}%
        {{hash=ce1735ae9d2385be01e51f6968c9a51a}{%
           family={Rusted},
           familyi={R\bibinitperiod},
           given={Jennifer},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{094642f9ae285c8a2cce0146945f9242}
      \strng{fullhash}{9b2085ac4b6439b0ecba9b3bbbeab71c}
      \strng{bibnamehash}{9b2085ac4b6439b0ecba9b3bbbeab71c}
      \strng{authorbibnamehash}{9b2085ac4b6439b0ecba9b3bbbeab71c}
      \strng{authornamehash}{094642f9ae285c8a2cce0146945f9242}
      \strng{authorfullhash}{9b2085ac4b6439b0ecba9b3bbbeab71c}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The aim of this study was to determine the pattern of fixations during the performance of a well-learned task in a natural setting (making tea), and to classify the types of monitoring action that the eyes perform. We used a head-mounted eye-movement video camera, which provided a continuous view of the scene ahead, with a dot indicating foveal direction with an accuracy of about 1 deg. A second video camera recorded the subject's activities from across the room. The videos were linked and analysed frame by frame. Foveal direction was always close to the object being manipulated, and very few fixations were irrelevant to the task. The first object-related fixation typically led the first indication of manipulation by 0.56 s, and vision moved to the next object about 0.61 s before manipulation of the previous object was complete. Each object-related act that did not involve a waiting period lasted an average of 3.3 s and involved about 7 fixations. Roughly a third of all fixations on objects could be definitely identified with one of four monitoring functions: locating objects used later in the process, directing the hand or object in the hand to a new location, guiding the approach of one object to another (eg kettle and lid), and checking the state of some variable (eg water level). We conclude that although the actions of tea-making are `automated' and proceed with little conscious involvement, the eyes closely monitor every step of the process. This type of unconscious attention must be a common phenomenon in everyday life.}
      \field{issn}{0301-0066, 1468-4233}
      \field{journaltitle}{Perception}
      \field{month}{11}
      \field{number}{11}
      \field{title}{The {Roles} of {Vision} and {Eye} {Movements} in the {Control} of {Activities} of {Daily} {Living}}
      \field{urlday}{21}
      \field{urlmonth}{11}
      \field{urlyear}{2023}
      \field{volume}{28}
      \field{year}{1999}
      \field{urldateera}{ce}
      \field{pages}{1311\bibrangedash 1328}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1068/p2935
      \endverb
      \verb{file}
      \verb Land et al. - 1999 - The Roles of Vision and Eye Movements in the Contr.pdf:/Users/mengze/Zotero/storage/US6MQIN3/Land et al. - 1999 - The Roles of Vision and Eye Movements in the Contr.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://journals.sagepub.com/doi/10.1068/p2935
      \endverb
      \verb{url}
      \verb http://journals.sagepub.com/doi/10.1068/p2935
      \endverb
    \endentry
    \entry{huang_predicting_2018}{misc}{}
      \name{author}{4}{}{%
        {{hash=a674a5619fc006f5693d644d35613257}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yifei},
           giveni={Y\bibinitperiod}}}%
        {{hash=f5812c2f5a852b890572af702630b317}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Minjie},
           giveni={M\bibinitperiod}}}%
        {{hash=6d8430858f6105d3c3154a17ff3ef5c6}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zhenqiang},
           giveni={Z\bibinitperiod}}}%
        {{hash=e292ab2afea048f7ad6399d6b3301f67}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Yoichi},
           giveni={Y\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{671cc73eec0e808b0406282711a07b84}
      \strng{fullhash}{6ffe570045fc202d65d2cc38692deb14}
      \strng{bibnamehash}{6ffe570045fc202d65d2cc38692deb14}
      \strng{authorbibnamehash}{6ffe570045fc202d65d2cc38692deb14}
      \strng{authornamehash}{671cc73eec0e808b0406282711a07b84}
      \strng{authorfullhash}{6ffe570045fc202d65d2cc38692deb14}
      \field{extraname}{2}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a new computational model for gaze prediction in egocentric videos by exploring patterns in temporal shift of gaze fixations (attention transition) that are dependent on egocentric manipulation tasks. Our assumption is that the high-level context of how a task is completed in a certain way has a strong influence on attention transition and should be modeled for gaze prediction in natural dynamic scenes. Specifically, we propose a hybrid model based on deep neural networks which integrates task-dependent attention transition with bottom-up saliency prediction. In particular, the task-dependent attention transition is learned with a recurrent neural network to exploit the temporal context of gaze fixations, e.g. looking at a cup after moving gaze away from a grasped bottle. Experiments on public egocentric activity datasets show that our model significantly outperforms state-of-the-art gaze prediction methods and is able to learn meaningful transition of human attention.}
      \field{month}{12}
      \field{note}{arXiv:1803.09125 [cs]}
      \field{title}{Predicting {Gaze} in {Egocentric} {Video} by {Learning} {Task}-dependent {Attention} {Transition}}
      \field{year}{2018}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/8RA8CPJU/Huang et al. - 2018 - Predicting Gaze in Egocentric Video by Learning Ta.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/FS7EE9VC/1803.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1803.09125
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1803.09125
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{tavakoli_digging_2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=04f5b0d8c4011a27cf4b6e65843ce620}{%
           family={Tavakoli},
           familyi={T\bibinitperiod},
           given={Hamed\bibnamedelima Rezazadegan},
           giveni={H\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=37fd31b198921b49b17c45a3909e5412}{%
           family={Rahtu},
           familyi={R\bibinitperiod},
           given={Esa},
           giveni={E\bibinitperiod}}}%
        {{hash=8d20e3f80f9d860f9a91b6f18054e4b1}{%
           family={Kannala},
           familyi={K\bibinitperiod},
           given={Juho},
           giveni={J\bibinitperiod}}}%
        {{hash=ac96d0501ac3e57fa3d92d318b45fc31}{%
           family={Borji},
           familyi={B\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Waikoloa Village, HI, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{dc107d88e2d2dfcd7a48234e22e6f34e}
      \strng{fullhash}{d569c153ddd38786e9ae275c819a5eee}
      \strng{bibnamehash}{d569c153ddd38786e9ae275c819a5eee}
      \strng{authorbibnamehash}{d569c153ddd38786e9ae275c819a5eee}
      \strng{authornamehash}{dc107d88e2d2dfcd7a48234e22e6f34e}
      \strng{authorfullhash}{d569c153ddd38786e9ae275c819a5eee}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2019 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})}
      \field{isbn}{978-1-72811-975-5}
      \field{month}{1}
      \field{title}{Digging {Deeper} {Into} {Egocentric} {Gaze} {Prediction}}
      \field{year}{2019}
      \field{pages}{273\bibrangedash 282}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/WACV.2019.00035
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/mengze/Zotero/storage/VW8PSLIE/Tavakoli et al. - 2019 - Digging Deeper Into Egocentric Gaze Prediction.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8658619/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8658619/
      \endverb
    \endentry
    \entry{lai_eye_2022}{misc}{}
      \name{author}{4}{}{%
        {{hash=2f06b2f23877ee985a30d473ea15fb59}{%
           family={Lai},
           familyi={L\bibinitperiod},
           given={Bolin},
           giveni={B\bibinitperiod}}}%
        {{hash=0474cc7d2cd3785ad22074a7b4abeb8b}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Miao},
           giveni={M\bibinitperiod}}}%
        {{hash=9bcfb1ef4d6824ad8f58b9b2bd64ab24}{%
           family={Ryan},
           familyi={R\bibinitperiod},
           given={Fiona},
           giveni={F\bibinitperiod}}}%
        {{hash=7ad025a3ff50080dd4f4ff689ab4d020}{%
           family={Rehg},
           familyi={R\bibinitperiod},
           given={James\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ca3f61af229dcc0326598536137879c0}
      \strng{fullhash}{55a80062deda79441d7423ecd0426254}
      \strng{bibnamehash}{55a80062deda79441d7423ecd0426254}
      \strng{authorbibnamehash}{55a80062deda79441d7423ecd0426254}
      \strng{authornamehash}{ca3f61af229dcc0326598536137879c0}
      \strng{authorfullhash}{55a80062deda79441d7423ecd0426254}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present the first transformer-based model to address the challenging problem of egocentric gaze estimation. We observe that the connection between the global scene context and local visual information is vital for localizing the gaze fixation from egocentric video frames. To this end, we design the transformer encoder to embed the global context as one additional visual token and further propose a novel Global-Local Correlation (GLC) module to explicitly model the correlation of the global token and each local token. We validate our model on two egocentric video datasets - EGTEA Gaze+ and Ego4D. Our detailed ablation studies demonstrate the benefits of our method. In addition, our approach exceeds previous state-of-the-arts by a large margin. We also provide additional visualizations to support our claim that global-local correlation serves a key representation for predicting gaze fixation from egocentric videos. More details can be found in our website (https://bolinlai.github.io/GLC-EgoGazeEst).}
      \field{month}{8}
      \field{note}{arXiv:2208.04464 [cs]}
      \field{shorttitle}{In the {Eye} of {Transformer}}
      \field{title}{In the {Eye} of {Transformer}: {Global}-{Local} {Correlation} for {Egocentric} {Gaze} {Estimation}}
      \field{year}{2022}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/4TNKX5JQ/Lai et al. - 2022 - In the Eye of Transformer Global-Local Correlatio.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/66ZSRTXD/2208.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2208.04464
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2208.04464
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{li_eye_2020}{misc}{}
      \name{author}{3}{}{%
        {{hash=07e26844b73cfbeb7f20e73779d321e4}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yin},
           giveni={Y\bibinitperiod}}}%
        {{hash=0474cc7d2cd3785ad22074a7b4abeb8b}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Miao},
           giveni={M\bibinitperiod}}}%
        {{hash=7ad025a3ff50080dd4f4ff689ab4d020}{%
           family={Rehg},
           familyi={R\bibinitperiod},
           given={James\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{580d36fe75f3527298dfd9cc0f161024}
      \strng{fullhash}{f9e29f5c4e4c83eea82a375bcc99bd90}
      \strng{bibnamehash}{f9e29f5c4e4c83eea82a375bcc99bd90}
      \strng{authorbibnamehash}{f9e29f5c4e4c83eea82a375bcc99bd90}
      \strng{authornamehash}{580d36fe75f3527298dfd9cc0f161024}
      \strng{authorfullhash}{f9e29f5c4e4c83eea82a375bcc99bd90}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We address the task of jointly determining what a person is doing and where they are looking based on the analysis of video captured by a headworn camera. To facilitate our research, we first introduce the EGTEA Gaze+ dataset. Our dataset comes with videos, gaze tracking data, hand masks and action annotations, thereby providing the most comprehensive benchmark for First Person Vision (FPV). Moving beyond the dataset, we propose a novel deep model for joint gaze estimation and action recognition in FPV. Our method describes the participant's gaze as a probabilistic variable and models its distribution using stochastic units in a deep network. We further sample from these stochastic units, generating an attention map to guide the aggregation of visual features for action recognition. Our method is evaluated on our EGTEA Gaze+ dataset and achieves a performance level that exceeds the state-of-the-art by a significant margin. More importantly, we demonstrate that our model can be applied to larger scale FPV dataset---EPIC-Kitchens even without using gaze, offering new state-of-the-art results on FPV action recognition.}
      \field{month}{10}
      \field{note}{arXiv:2006.00626 [cs]}
      \field{shorttitle}{In the {Eye} of the {Beholder}}
      \field{title}{In the {Eye} of the {Beholder}: {Gaze} and {Actions} in {First} {Person} {Video}}
      \field{year}{2020}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/CRYFL62N/Li et al. - 2020 - In the Eye of the Beholder Gaze and Actions in Fi.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/9HMU6UKM/2006.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2006.00626
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2006.00626
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{grauman_ego4d_2022}{misc}{}
      \name{author}{85}{}{%
        {{hash=f67e08fa64fd602c4ec562da14d65216}{%
           family={Grauman},
           familyi={G\bibinitperiod},
           given={Kristen},
           giveni={K\bibinitperiod}}}%
        {{hash=c1d55430696ff4be1ca2bf1354cb35c0}{%
           family={Westbury},
           familyi={W\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=6972b4f6ba94ec4706e0ea9a9a9a02b2}{%
           family={Byrne},
           familyi={B\bibinitperiod},
           given={Eugene},
           giveni={E\bibinitperiod}}}%
        {{hash=c6cb4058244d988924992cbb0afa0c85}{%
           family={Chavis},
           familyi={C\bibinitperiod},
           given={Zachary},
           giveni={Z\bibinitperiod}}}%
        {{hash=01ee2926b820b5688c1319ef75c3ee21}{%
           family={Furnari},
           familyi={F\bibinitperiod},
           given={Antonino},
           giveni={A\bibinitperiod}}}%
        {{hash=b04a9f34a16019be789d119ecef9ae8b}{%
           family={Girdhar},
           familyi={G\bibinitperiod},
           given={Rohit},
           giveni={R\bibinitperiod}}}%
        {{hash=d50c94e3463297a6caa8745196b2070d}{%
           family={Hamburger},
           familyi={H\bibinitperiod},
           given={Jackson},
           giveni={J\bibinitperiod}}}%
        {{hash=1e6f26f32c3e6d7ca8348e5ee752a8e6}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=0474cc7d2cd3785ad22074a7b4abeb8b}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Miao},
           giveni={M\bibinitperiod}}}%
        {{hash=5083934345ec318642dde5e475dc027a}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Xingyu},
           giveni={X\bibinitperiod}}}%
        {{hash=ba53db30b1082534e47dca0239f7c491}{%
           family={Martin},
           familyi={M\bibinitperiod},
           given={Miguel},
           giveni={M\bibinitperiod}}}%
        {{hash=41f0b813379a0fd1e4768cb3d6c8b2be}{%
           family={Nagarajan},
           familyi={N\bibinitperiod},
           given={Tushar},
           giveni={T\bibinitperiod}}}%
        {{hash=32c718910444fa00a38cef8dd3c90c30}{%
           family={Radosavovic},
           familyi={R\bibinitperiod},
           given={Ilija},
           giveni={I\bibinitperiod}}}%
        {{hash=685a843357e3dad881c03819570926ec}{%
           family={Ramakrishnan},
           familyi={R\bibinitperiod},
           given={Santhosh\bibnamedelima Kumar},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=9bcfb1ef4d6824ad8f58b9b2bd64ab24}{%
           family={Ryan},
           familyi={R\bibinitperiod},
           given={Fiona},
           giveni={F\bibinitperiod}}}%
        {{hash=72ed728b4c96dedc25bb66bebc9590c2}{%
           family={Sharma},
           familyi={S\bibinitperiod},
           given={Jayant},
           giveni={J\bibinitperiod}}}%
        {{hash=98eea0df034e53378a945ed4a8d14b99}{%
           family={Wray},
           familyi={W\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=28c3664d45706df83040ece01b12dd8f}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Mengmeng},
           giveni={M\bibinitperiod}}}%
        {{hash=fd3faf3d57931966c3fa105a6c1f4163}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Eric\bibnamedelima Zhongcong},
           giveni={E\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=996dee7706b2e1bbd3535f5f442606fc}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Chen},
           giveni={C\bibinitperiod}}}%
        {{hash=00b8aa53f7cf375dab35803dcff06a0c}{%
           family={Bansal},
           familyi={B\bibinitperiod},
           given={Siddhant},
           giveni={S\bibinitperiod}}}%
        {{hash=d0a408119272ca1bd49b625e3b927d05}{%
           family={Batra},
           familyi={B\bibinitperiod},
           given={Dhruv},
           giveni={D\bibinitperiod}}}%
        {{hash=f4f2127014d1cfd5c770037f3a9bd9c9}{%
           family={Cartillier},
           familyi={C\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod}}}%
        {{hash=4cfe89e57aabf7133a5e54eecd6f0e56}{%
           family={Crane},
           familyi={C\bibinitperiod},
           given={Sean},
           giveni={S\bibinitperiod}}}%
        {{hash=26c1f83832b94cab859aa0c4da3aebff}{%
           family={Do},
           familyi={D\bibinitperiod},
           given={Tien},
           giveni={T\bibinitperiod}}}%
        {{hash=9bc6578980edbce8d8fdaf76a11dc95b}{%
           family={Doulaty},
           familyi={D\bibinitperiod},
           given={Morrie},
           giveni={M\bibinitperiod}}}%
        {{hash=68fb15c6272d3511790255cf13c5b8c1}{%
           family={Erapalli},
           familyi={E\bibinitperiod},
           given={Akshay},
           giveni={A\bibinitperiod}}}%
        {{hash=bd2fff33d3a5433188d2662695e79eb5}{%
           family={Feichtenhofer},
           familyi={F\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=578e0f42891c2326e57ea1094d9b767a}{%
           family={Fragomeni},
           familyi={F\bibinitperiod},
           given={Adriano},
           giveni={A\bibinitperiod}}}%
        {{hash=1164f9044f6f41c4b857aff42cf2b261}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Qichen},
           giveni={Q\bibinitperiod}}}%
        {{hash=512ab06e0b7db214be71283bddab2e44}{%
           family={Gebreselasie},
           familyi={G\bibinitperiod},
           given={Abrham},
           giveni={A\bibinitperiod}}}%
        {{hash=ca5428aee612d2f618a21f53c4cf1852}{%
           family={Gonzalez},
           familyi={G\bibinitperiod},
           given={Cristina},
           giveni={C\bibinitperiod}}}%
        {{hash=1eba9def263d35101c48c5f9f215ea71}{%
           family={Hillis},
           familyi={H\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=8a4040e2f968b8779edd02addd028a9e}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Xuhua},
           giveni={X\bibinitperiod}}}%
        {{hash=a674a5619fc006f5693d644d35613257}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yifei},
           giveni={Y\bibinitperiod}}}%
        {{hash=75bfdfed526a63dd37495d9a120a26e5}{%
           family={Jia},
           familyi={J\bibinitperiod},
           given={Wenqi},
           giveni={W\bibinitperiod}}}%
        {{hash=40095bb2d5b0b9946132f2df409683c9}{%
           family={Khoo},
           familyi={K\bibinitperiod},
           given={Weslie},
           giveni={W\bibinitperiod}}}%
        {{hash=8a5683bc72a65b46517efaf0b5df0fce}{%
           family={Kolar},
           familyi={K\bibinitperiod},
           given={Jachym},
           giveni={J\bibinitperiod}}}%
        {{hash=cff8967849ae28fa040a2c31360f5f70}{%
           family={Kottur},
           familyi={K\bibinitperiod},
           given={Satwik},
           giveni={S\bibinitperiod}}}%
        {{hash=f8ca7fee112f8a7d0d22270baf5f7b02}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Anurag},
           giveni={A\bibinitperiod}}}%
        {{hash=0af0411416a8a01f661458602bdf63d8}{%
           family={Landini},
           familyi={L\bibinitperiod},
           given={Federico},
           giveni={F\bibinitperiod}}}%
        {{hash=ad699cc0ff44aa8ef2a872dab8e20175}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Chao},
           giveni={C\bibinitperiod}}}%
        {{hash=46e2e0b282bd98dcc736b344f4c7274f}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yanghao},
           giveni={Y\bibinitperiod}}}%
        {{hash=6d8430858f6105d3c3154a17ff3ef5c6}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Zhenqiang},
           giveni={Z\bibinitperiod}}}%
        {{hash=f4c0f5b01a59bce67524ce12afff9671}{%
           family={Mangalam},
           familyi={M\bibinitperiod},
           given={Karttikeya},
           giveni={K\bibinitperiod}}}%
        {{hash=301641d8ceb74d4bbce4d8ab8e1fd6f9}{%
           family={Modhugu},
           familyi={M\bibinitperiod},
           given={Raghava},
           giveni={R\bibinitperiod}}}%
        {{hash=3cf5b038eab6d058826fe8933fcdc191}{%
           family={Munro},
           familyi={M\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=9ba519851cc925dddca3ec941f33d7c3}{%
           family={Murrell},
           familyi={M\bibinitperiod},
           given={Tullie},
           giveni={T\bibinitperiod}}}%
        {{hash=d3ff7e69d548d4264f15a97fd9a05118}{%
           family={Nishiyasu},
           familyi={N\bibinitperiod},
           given={Takumi},
           giveni={T\bibinitperiod}}}%
        {{hash=4f32e69ba9b4bb917b4843f7045e0dff}{%
           family={Price},
           familyi={P\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod}}}%
        {{hash=3c1e5f502c9468b360986f957488d4c7}{%
           family={Puentes},
           familyi={P\bibinitperiod},
           given={Paola\bibnamedelima Ruiz},
           giveni={P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=9d89afdbde316ad76b9dc963b94735b4}{%
           family={Ramazanova},
           familyi={R\bibinitperiod},
           given={Merey},
           giveni={M\bibinitperiod}}}%
        {{hash=f3ec181b49d8eea41d47adca054d6e5c}{%
           family={Sari},
           familyi={S\bibinitperiod},
           given={Leda},
           giveni={L\bibinitperiod}}}%
        {{hash=8cd95915c9e81f6c6053469e968480d8}{%
           family={Somasundaram},
           familyi={S\bibinitperiod},
           given={Kiran},
           giveni={K\bibinitperiod}}}%
        {{hash=2ab596264c21cad707b07937be87ff85}{%
           family={Southerland},
           familyi={S\bibinitperiod},
           given={Audrey},
           giveni={A\bibinitperiod}}}%
        {{hash=51cf04b24c0936c46178f8088ab89999}{%
           family={Sugano},
           familyi={S\bibinitperiod},
           given={Yusuke},
           giveni={Y\bibinitperiod}}}%
        {{hash=0c8e8b48f54f75293b29d6d028250144}{%
           family={Tao},
           familyi={T\bibinitperiod},
           given={Ruijie},
           giveni={R\bibinitperiod}}}%
        {{hash=13ec24171bb4e1731e1f1605c1731fb2}{%
           family={Vo},
           familyi={V\bibinitperiod},
           given={Minh},
           giveni={M\bibinitperiod}}}%
        {{hash=7040b0ee84aa8faa71784490465f931b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yuchen},
           giveni={Y\bibinitperiod}}}%
        {{hash=6a7e8c963bb87e86da0291d60e21a3ca}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Xindi},
           giveni={X\bibinitperiod}}}%
        {{hash=b9556c42e71a854d219307f35c58b82d}{%
           family={Yagi},
           familyi={Y\bibinitperiod},
           given={Takuma},
           giveni={T\bibinitperiod}}}%
        {{hash=a3f6b11a6c0ad6d5172ce5f91c4cd109}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Ziwei},
           giveni={Z\bibinitperiod}}}%
        {{hash=47117b44eaf419b58d07d3d515ad28d4}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Yunyi},
           giveni={Y\bibinitperiod}}}%
        {{hash=d19aeb8b8cfa243de387a3e46d05bcc6}{%
           family={Arbelaez},
           familyi={A\bibinitperiod},
           given={Pablo},
           giveni={P\bibinitperiod}}}%
        {{hash=ad088a3a3d223a5587599809f39cd1f7}{%
           family={Crandall},
           familyi={C\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=712adc8e0e74b98a58fbf432290180d2}{%
           family={Damen},
           familyi={D\bibinitperiod},
           given={Dima},
           giveni={D\bibinitperiod}}}%
        {{hash=a79bf15b29522f05fc8a35b7bab3bc47}{%
           family={Farinella},
           familyi={F\bibinitperiod},
           given={Giovanni\bibnamedelima Maria},
           giveni={G\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=79920cfb27ccfc2953f9e5bde69e54f6}{%
           family={Fuegen},
           familyi={F\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=6e340bd126f740dfedce8191fbd2eb36}{%
           family={Ghanem},
           familyi={G\bibinitperiod},
           given={Bernard},
           giveni={B\bibinitperiod}}}%
        {{hash=ac089effa859634894f5cc65518cf0d0}{%
           family={Ithapu},
           familyi={I\bibinitperiod},
           given={Vamsi\bibnamedelima Krishna},
           giveni={V\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=c28cbc2901395b4ae713740941e45d6f}{%
           family={Jawahar},
           familyi={J\bibinitperiod},
           given={C.\bibnamedelimi V.},
           giveni={C\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=e58101cdbab2bf36acfe947dd4201a1c}{%
           family={Joo},
           familyi={J\bibinitperiod},
           given={Hanbyul},
           giveni={H\bibinitperiod}}}%
        {{hash=4e4b95cc7070ea5a03c13bea9ba5c5e5}{%
           family={Kitani},
           familyi={K\bibinitperiod},
           given={Kris},
           giveni={K\bibinitperiod}}}%
        {{hash=f397ee85433a25b75738faa0b764e496}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haizhou},
           giveni={H\bibinitperiod}}}%
        {{hash=239670d06a0c3f1468b54a7264838ce6}{%
           family={Newcombe},
           familyi={N\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod}}}%
        {{hash=b7446de83b2320d904225a0730e3389a}{%
           family={Oliva},
           familyi={O\bibinitperiod},
           given={Aude},
           giveni={A\bibinitperiod}}}%
        {{hash=037bd7a0f977c1652ba8a80d04e8df25}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Hyun\bibnamedelima Soo},
           giveni={H\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=7ad025a3ff50080dd4f4ff689ab4d020}{%
           family={Rehg},
           familyi={R\bibinitperiod},
           given={James\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=e292ab2afea048f7ad6399d6b3301f67}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Yoichi},
           giveni={Y\bibinitperiod}}}%
        {{hash=159989720a07cffdf1f8afdcf19f925d}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Jianbo},
           giveni={J\bibinitperiod}}}%
        {{hash=b2808cc4100eda648ca39e1199d6bfea}{%
           family={Shou},
           familyi={S\bibinitperiod},
           given={Mike\bibnamedelima Zheng},
           giveni={M\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=2a80dd1cae02059e95bfed2f2715fd0a}{%
           family={Torralba},
           familyi={T\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
        {{hash=7174975989c609900098ef361edc9286}{%
           family={Torresani},
           familyi={T\bibinitperiod},
           given={Lorenzo},
           giveni={L\bibinitperiod}}}%
        {{hash=a76494925059ff5b3543a093d868f6b7}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Mingfei},
           giveni={M\bibinitperiod}}}%
        {{hash=c75a5377b6dc5213831576e88ffe553c}{%
           family={Malik},
           familyi={M\bibinitperiod},
           given={Jitendra},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{fb7a5511286b06ea803b98de3745a3c8}
      \strng{fullhash}{56fedd074baa84efaa8378ae45fd3af4}
      \strng{bibnamehash}{56fedd074baa84efaa8378ae45fd3af4}
      \strng{authorbibnamehash}{56fedd074baa84efaa8378ae45fd3af4}
      \strng{authornamehash}{fb7a5511286b06ea803b98de3745a3c8}
      \strng{authorfullhash}{56fedd074baa84efaa8378ae45fd3af4}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce Ego4D, a massive-scale egocentric video dataset and benchmark suite. It offers 3,670 hours of daily-life activity video spanning hundreds of scenarios (household, outdoor, workplace, leisure, etc.) captured by 931 unique camera wearers from 74 worldwide locations and 9 different countries. The approach to collection is designed to uphold rigorous privacy and ethics standards with consenting participants and robust de-identification procedures where relevant. Ego4D dramatically expands the volume of diverse egocentric video footage publicly available to the research community. Portions of the video are accompanied by audio, 3D meshes of the environment, eye gaze, stereo, and/or synchronized videos from multiple egocentric cameras at the same event. Furthermore, we present a host of new benchmark challenges centered around understanding the first-person visual experience in the past (querying an episodic memory), present (analyzing hand-object manipulation, audio-visual conversation, and social interactions), and future (forecasting activities). By publicly sharing this massive annotated dataset and benchmark suite, we aim to push the frontier of first-person perception. Project page: https://ego4d-data.org/}
      \field{month}{3}
      \field{note}{arXiv:2110.07058 [cs]}
      \field{shorttitle}{{Ego4D}}
      \field{title}{{Ego4D}: {Around} the {World} in 3,000 {Hours} of {Egocentric} {Video}}
      \field{year}{2022}
      \verb{urlraw}
      \verb http://arxiv.org/abs/2110.07058
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2110.07058
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Artificial Intelligence}
    \endentry
    \entry{zhu2020comprehensive}{misc}{}
      \name{author}{10}{}{%
        {{hash=017c8fdccfa4d7fe6b3cf42ea7acad7a}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
        {{hash=f7b213026e6a37ccf33b05453fb861ad}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xinyu},
           giveni={X\bibinitperiod}}}%
        {{hash=bb62e5b1f8b5a07ce116ddd7ad0608ab}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Chunhui},
           giveni={C\bibinitperiod}}}%
        {{hash=491f762d8a0512f957335f39e40a6a79}{%
           family={Zolfaghari},
           familyi={Z\bibinitperiod},
           given={Mohammadreza},
           giveni={M\bibinitperiod}}}%
        {{hash=d5051eb0f62df89577bc02f764c3f11a}{%
           family={Xiong},
           familyi={X\bibinitperiod},
           given={Yuanjun},
           giveni={Y\bibinitperiod}}}%
        {{hash=f3d25f99c890af62c2b1bbb4279f58dc}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Chongruo},
           giveni={C\bibinitperiod}}}%
        {{hash=b96e05ed0e1b08189597f7c933749b97}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhi},
           giveni={Z\bibinitperiod}}}%
        {{hash=6039ac67d556a71cf00264cdd2078252}{%
           family={Tighe},
           familyi={T\bibinitperiod},
           given={Joseph},
           giveni={J\bibinitperiod}}}%
        {{hash=60a32cd5fa44af52bd57f89f099bca97}{%
           family={Manmatha},
           familyi={M\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=c4a02f87e51fc72ab3f841de1a3982a7}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{3108a83d16830deadfaa48fcad64cb77}
      \strng{fullhash}{c8f02f12cdc99c1cd6c91af562acc989}
      \strng{bibnamehash}{c8f02f12cdc99c1cd6c91af562acc989}
      \strng{authorbibnamehash}{c8f02f12cdc99c1cd6c91af562acc989}
      \strng{authornamehash}{3108a83d16830deadfaa48fcad64cb77}
      \strng{authorfullhash}{c8f02f12cdc99c1cd6c91af562acc989}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{title}{A Comprehensive Study of Deep Video Action Recognition}
      \field{year}{2020}
      \verb{eprint}
      \verb 2012.06567
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/2012.06567
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/2012.06567
      \endverb
    \endentry
    \entry{karpathy_large-scale_2014}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=e91a4c2044bccdbef249eabc886ff988}{%
           family={Karpathy},
           familyi={K\bibinitperiod},
           given={Andrej},
           giveni={A\bibinitperiod}}}%
        {{hash=61782a3924be97d5dc42427bfd963c92}{%
           family={Toderici},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=80447d80622f52e6a11d35ede2ff3160}{%
           family={Shetty},
           familyi={S\bibinitperiod},
           given={Sanketh},
           giveni={S\bibinitperiod}}}%
        {{hash=909cc514625b20b174a78f5dcd8e558a}{%
           family={Leung},
           familyi={L\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=4df216303596d3f13ec1677ee7718dca}{%
           family={Sukthankar},
           familyi={S\bibinitperiod},
           given={Rahul},
           giveni={R\bibinitperiod}}}%
        {{hash=cd00ce5bc45f687c432e52e0fa1a7aa6}{%
           family={Fei-Fei},
           familyi={F\bibinithyphendelim F\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Columbus, OH, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{66b96c710eb5c440c8d6cd3c52cb0528}
      \strng{fullhash}{9a16f277a516dbef5f366670cef2658e}
      \strng{bibnamehash}{9a16f277a516dbef5f366670cef2658e}
      \strng{authorbibnamehash}{9a16f277a516dbef5f366670cef2658e}
      \strng{authornamehash}{66b96c710eb5c440c8d6cd3c52cb0528}
      \strng{authorfullhash}{9a16f277a516dbef5f366670cef2658e}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}}
      \field{isbn}{978-1-4799-5118-5}
      \field{month}{6}
      \field{title}{Large-{Scale} {Video} {Classification} with {Convolutional} {Neural} {Networks}}
      \field{urlday}{21}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{urldateera}{ce}
      \field{pages}{1725\bibrangedash 1732}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/CVPR.2014.223
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/mengze/Zotero/storage/789M5RY8/Karpathy et al. - 2014 - Large-Scale Video Classification with Convolutiona.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6909619
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6909619
      \endverb
    \endentry
    \entry{WangXW0LTG16}{article}{}
      \name{author}{7}{}{%
        {{hash=19e9bfb93cd5f50de827a51431a8d010}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Limin},
           giveni={L\bibinitperiod}}}%
        {{hash=d5051eb0f62df89577bc02f764c3f11a}{%
           family={Xiong},
           familyi={X\bibinitperiod},
           given={Yuanjun},
           giveni={Y\bibinitperiod}}}%
        {{hash=edcb27361de88ed2a8ec1c9dca30dd7a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhe},
           giveni={Z\bibinitperiod}}}%
        {{hash=2addc56ce0ea3a8fc05ff9b0995f74f4}{%
           family={Qiao},
           familyi={Q\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=f4033e88b680ba7279a268e75f80b1d3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Dahua},
           giveni={D\bibinitperiod}}}%
        {{hash=7e09524e32e7b51c169850f848787677}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Xiaoou},
           giveni={X\bibinitperiod}}}%
        {{hash=4e3c4333156c93f2e568db6387d4c7f1}{%
           family={Gool},
           familyi={G\bibinitperiod},
           given={Luc\bibnamedelima Van},
           giveni={L\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{c5989e5d35c513cda241d5030fd85d29}
      \strng{fullhash}{2abbbac9da2cef1dc77181a854715d67}
      \strng{bibnamehash}{2abbbac9da2cef1dc77181a854715d67}
      \strng{authorbibnamehash}{2abbbac9da2cef1dc77181a854715d67}
      \strng{authornamehash}{c5989e5d35c513cda241d5030fd85d29}
      \strng{authorfullhash}{2abbbac9da2cef1dc77181a854715d67}
      \field{extraname}{1}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{CoRR}
      \field{title}{Temporal Segment Networks: Towards Good Practices for Deep Action Recognition}
      \field{volume}{abs/1608.00859}
      \field{year}{2016}
      \verb{eprint}
      \verb 1608.00859
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1608.00859
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1608.00859
      \endverb
    \endentry
    \entry{lin_tsm_2019}{misc}{}
      \name{author}{3}{}{%
        {{hash=f7dc0ae05140014a83b76c5ea171577c}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Ji},
           giveni={J\bibinitperiod}}}%
        {{hash=97044e575d3c0a3dd2551779810add07}{%
           family={Gan},
           familyi={G\bibinitperiod},
           given={Chuang},
           giveni={C\bibinitperiod}}}%
        {{hash=873e4e07ff73d563d2651d20ffaf99e0}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Song},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{854abd7200b26cfc95a45e627cefb855}
      \strng{fullhash}{b1a1d5b21ce93cb84f9841138d00444b}
      \strng{bibnamehash}{b1a1d5b21ce93cb84f9841138d00444b}
      \strng{authorbibnamehash}{b1a1d5b21ce93cb84f9841138d00444b}
      \strng{authornamehash}{854abd7200b26cfc95a45e627cefb855}
      \strng{authorfullhash}{b1a1d5b21ce93cb84f9841138d00444b}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The explosive growth in video streaming gives rise to challenges on performing video understanding at high accuracy and low computation cost. Conventional 2D CNNs are computationally cheap but cannot capture temporal relationships; 3D CNN based methods can achieve good performance but are computationally intensive, making it expensive to deploy. In this paper, we propose a generic and effective Temporal Shift Module (TSM) that enjoys both high efficiency and high performance. Specifically, it can achieve the performance of 3D CNN but maintain 2D CNN's complexity. TSM shifts part of the channels along the temporal dimension; thus facilitate information exchanged among neighboring frames. It can be inserted into 2D CNNs to achieve temporal modeling at zero computation and zero parameters. We also extended TSM to online setting, which enables real-time low-latency online video recognition and video object detection. TSM is accurate and efficient: it ranks the first place on the Something-Something leaderboard upon publication; on Jetson Nano and Galaxy Note8, it achieves a low latency of 13ms and 35ms for online video recognition. The code is available at: https://github.com/mit-han-lab/temporal-shift-module.}
      \field{month}{8}
      \field{note}{arXiv:1811.08383 [cs]}
      \field{shorttitle}{{TSM}}
      \field{title}{{TSM}: {Temporal} {Shift} {Module} for {Efficient} {Video} {Understanding}}
      \field{urlday}{21}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/QCH48WXP/Lin et al. - 2019 - TSM Temporal Shift Module for Efficient Video Und.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/JJ94IZJ3/1811.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1811.08383
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1811.08383
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{damen_epic-kitchens_2021}{article}{}
      \name{author}{11}{}{%
        {{hash=712adc8e0e74b98a58fbf432290180d2}{%
           family={Damen},
           familyi={D\bibinitperiod},
           given={Dima},
           giveni={D\bibinitperiod}}}%
        {{hash=8a5f944371f0edd69817b054cf2fabea}{%
           family={Doughty},
           familyi={D\bibinitperiod},
           given={Hazel},
           giveni={H\bibinitperiod}}}%
        {{hash=a79bf15b29522f05fc8a35b7bab3bc47}{%
           family={Farinella},
           familyi={F\bibinitperiod},
           given={Giovanni\bibnamedelima Maria},
           giveni={G\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=132467c4a712be4725c988c89c68a30e}{%
           family={Fidler},
           familyi={F\bibinitperiod},
           given={Sanja},
           giveni={S\bibinitperiod}}}%
        {{hash=01ee2926b820b5688c1319ef75c3ee21}{%
           family={Furnari},
           familyi={F\bibinitperiod},
           given={Antonino},
           giveni={A\bibinitperiod}}}%
        {{hash=bd37d9c6d44a591d8b2882df82147ffe}{%
           family={Kazakos},
           familyi={K\bibinitperiod},
           given={Evangelos},
           giveni={E\bibinitperiod}}}%
        {{hash=6ccb227c9c28ae7723c60eecb7bcb3e2}{%
           family={Moltisanti},
           familyi={M\bibinitperiod},
           given={Davide},
           giveni={D\bibinitperiod}}}%
        {{hash=3cf5b038eab6d058826fe8933fcdc191}{%
           family={Munro},
           familyi={M\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=4a69412f6803494dcdfd4b4c60733a0c}{%
           family={Perrett},
           familyi={P\bibinitperiod},
           given={Toby},
           giveni={T\bibinitperiod}}}%
        {{hash=4f32e69ba9b4bb917b4843f7045e0dff}{%
           family={Price},
           familyi={P\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod}}}%
        {{hash=98eea0df034e53378a945ed4a8d14b99}{%
           family={Wray},
           familyi={W\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{2c5dace588eb8a2c5327df30ed07e18d}
      \strng{fullhash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{bibnamehash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{authorbibnamehash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{authornamehash}{2c5dace588eb8a2c5327df30ed07e18d}
      \strng{authorfullhash}{b3fb6f48a4bdc248122aef488d863382}
      \field{extraname}{1}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{issn}{0162-8828, 2160-9292, 1939-3539}
      \field{journaltitle}{IEEE Transactions on Pattern Analysis and Machine Intelligence}
      \field{month}{11}
      \field{number}{11}
      \field{shorttitle}{The {EPIC}-{KITCHENS} {Dataset}}
      \field{title}{The {EPIC}-{KITCHENS} {Dataset}: {Collection}, {Challenges} and {Baselines}}
      \field{volume}{43}
      \field{year}{2021}
      \field{pages}{4125\bibrangedash 4141}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1109/TPAMI.2020.2991965
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/mengze/Zotero/storage/GKFB935M/Damen et al. - 2021 - The EPIC-KITCHENS Dataset Collection, Challenges .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9084270/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9084270/
      \endverb
    \endentry
    \entry{sigurdsson_charades-ego_2018}{misc}{}
      \name{author}{5}{}{%
        {{hash=8dbbeb12b8ba51f34f30b7c941a1bcc4}{%
           family={Sigurdsson},
           familyi={S\bibinitperiod},
           given={Gunnar\bibnamedelima A.},
           giveni={G\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=83dd9d464c9f0ea982254939a7f021d8}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhinav},
           giveni={A\bibinitperiod}}}%
        {{hash=58e4a9845eac42a4b0e5205cf0970fc0}{%
           family={Schmid},
           familyi={S\bibinitperiod},
           given={Cordelia},
           giveni={C\bibinitperiod}}}%
        {{hash=396c6ddedb6f986906fc3e4994d19974}{%
           family={Farhadi},
           familyi={F\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod}}}%
        {{hash=073cc71ff9a77d7b122f010968a50bd6}{%
           family={Alahari},
           familyi={A\bibinitperiod},
           given={Karteek},
           giveni={K\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{7737528d95ccc1cfeab66db05a301a33}
      \strng{fullhash}{3a750e44bddcdedcff2e66dc16410791}
      \strng{bibnamehash}{3a750e44bddcdedcff2e66dc16410791}
      \strng{authorbibnamehash}{3a750e44bddcdedcff2e66dc16410791}
      \strng{authornamehash}{7737528d95ccc1cfeab66db05a301a33}
      \strng{authorfullhash}{3a750e44bddcdedcff2e66dc16410791}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In Actor and Observer we introduced a dataset linking the first and third-person video understanding domains, the Charades-Ego Dataset. In this paper we describe the egocentric aspect of the dataset and present annotations for Charades-Ego with 68,536 activity instances in 68.8 hours of first and third-person video, making it one of the largest and most diverse egocentric datasets available. Charades-Ego furthermore shares activity classes, scripts, and methodology with the Charades dataset, that consist of additional 82.3 hours of third-person video with 66,500 activity instances. Charades-Ego has temporal annotations and textual descriptions, making it suitable for egocentric video classification, localization, captioning, and new tasks utilizing the cross-modal nature of the data.}
      \field{month}{4}
      \field{note}{arXiv:1804.09626 [cs]}
      \field{shorttitle}{Charades-{Ego}}
      \field{title}{Charades-{Ego}: {A} {Large}-{Scale} {Dataset} of {Paired} {Third} and {First} {Person} {Videos}}
      \field{year}{2018}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/5HIH8SHC/Sigurdsson et al. - 2018 - Charades-Ego A Large-Scale Dataset of Paired Thir.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/6TK2RIKE/1804.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1804.09626
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1804.09626
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{herzig_object-region_2022}{misc}{}
      \name{author}{8}{}{%
        {{hash=217adba9290ad539efc57f03649e8be2}{%
           family={Herzig},
           familyi={H\bibinitperiod},
           given={Roei},
           giveni={R\bibinitperiod}}}%
        {{hash=07cbfaaf53c096bd1fc6926b1b6bfa10}{%
           family={Ben-Avraham},
           familyi={B\bibinithyphendelim A\bibinitperiod},
           given={Elad},
           giveni={E\bibinitperiod}}}%
        {{hash=f4c0f5b01a59bce67524ce12afff9671}{%
           family={Mangalam},
           familyi={M\bibinitperiod},
           given={Karttikeya},
           giveni={K\bibinitperiod}}}%
        {{hash=631fe4bc0e6930925abfc0dc8a78ef99}{%
           family={Bar},
           familyi={B\bibinitperiod},
           given={Amir},
           giveni={A\bibinitperiod}}}%
        {{hash=cb9892f91608c4c90c4bd75db5266cdf}{%
           family={Chechik},
           familyi={C\bibinitperiod},
           given={Gal},
           giveni={G\bibinitperiod}}}%
        {{hash=13bc852e29adb92e74f4de6b3a7b1f57}{%
           family={Rohrbach},
           familyi={R\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod}}}%
        {{hash=90180e1a30742e0d15328bfe637c2ef4}{%
           family={Darrell},
           familyi={D\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod}}}%
        {{hash=e8b604d0a7af5ee88043f8e31a4c6871}{%
           family={Globerson},
           familyi={G\bibinitperiod},
           given={Amir},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ab6f6a3555d41df351600af04b435553}
      \strng{fullhash}{cec25d72d4a3d876c0c81f2f5ce16040}
      \strng{bibnamehash}{cec25d72d4a3d876c0c81f2f5ce16040}
      \strng{authorbibnamehash}{cec25d72d4a3d876c0c81f2f5ce16040}
      \strng{authornamehash}{ab6f6a3555d41df351600af04b435553}
      \strng{authorfullhash}{cec25d72d4a3d876c0c81f2f5ce16040}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, video transformers have shown great success in video understanding, exceeding CNN performance; yet existing video transformer models do not explicitly model objects, although objects can be essential for recognizing actions. In this work, we present Object-Region Video Transformers (ORViT), an {\textbackslash}emph\{object-centric\} approach that extends video transformer layers with a block that directly incorporates object representations. The key idea is to fuse object-centric representations starting from early layers and propagate them into the transformer-layers, thus affecting the spatio-temporal representations throughout the network. Our ORViT block consists of two object-level streams: appearance and dynamics. In the appearance stream, an "Object-Region Attention" module applies self-attention over the patches and {\textbackslash}emph\{object regions\}. In this way, visual object regions interact with uniform patch tokens and enrich them with contextualized object information. We further model object dynamics via a separate "Object-Dynamics Module", which captures trajectory interactions, and show how to integrate the two streams. We evaluate our model on four tasks and five datasets: compositional and few-shot action recognition on SomethingElse, spatio-temporal action detection on AVA, and standard action recognition on Something-Something V2, Diving48 and Epic-Kitchen100. We show strong performance improvement across all tasks and datasets considered, demonstrating the value of a model that incorporates object representations into a transformer architecture. For code and pretrained models, visit the project page at {\textbackslash}url\{https://roeiherz.github.io/ORViT/\}}
      \field{month}{6}
      \field{note}{arXiv:2110.06915 [cs]}
      \field{title}{Object-{Region} {Video} {Transformers}}
      \field{year}{2022}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/ETMLBYV8/Herzig et al. - 2022 - Object-Region Video Transformers.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/C8ZQ6FLF/2110.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2110.06915
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2110.06915
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{wang_symbiotic_2020}{article}{}
      \name{author}{4}{}{%
        {{hash=cff37329ba828df7b7ffba7f6da650ef}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiaohan},
           giveni={X\bibinitperiod}}}%
        {{hash=497a9e1774032d32e4123020bfd16b7a}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=9e19f79cccbba87def2e30f14bce9253}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Linchao},
           giveni={L\bibinitperiod}}}%
        {{hash=446e84a6f09f26fc6cf5730853e551ba}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{bfaaa3b89e70ebb552070ffa58664255}
      \strng{fullhash}{3d68ca5a9949c957055652052977b4f3}
      \strng{bibnamehash}{3d68ca5a9949c957055652052977b4f3}
      \strng{authorbibnamehash}{3d68ca5a9949c957055652052977b4f3}
      \strng{authornamehash}{bfaaa3b89e70ebb552070ffa58664255}
      \strng{authorfullhash}{3d68ca5a9949c957055652052977b4f3}
      \field{extraname}{2}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Egocentric video recognition is a natural testbed for diverse interaction reasoning. Due to the large action vocabulary in egocentric video datasets, recent studies usually utilize a two-branch structure for action recognition, i.e., one branch for verb classification and the other branch for noun classification. However, correlation study between the verb and the noun branches have been largely ignored. Besides, the two branches fail to exploit local features due to the absence of position-aware attention mechanism. In this paper, we propose a novel Symbiotic Attention framework leveraging Privileged information (SAP) for egocentric video recognition. Finer position-aware object detection features can facilitate the understanding of actor's interaction with the object. We introduce these features in action recognition and regard them as privileged information. Our framework enables mutual communication among the verb branch, the noun branch, and the privileged information. This communication process not only injects local details into global features, but also exploits implicit guidance about the spatio-temporal position of an on-going action. We introduce a novel symbiotic attention (SA) to enable effective communication. It first normalizes the detection guided features on one branch to underline the action-relevant information from the other branch. SA adaptively enhances the interactions among the three sources. To further catalyze this communication, spatial relations are uncovered for the selection of most action-relevant information. It identifies the most valuable and discriminative feature for classification. We validate the effectiveness of our SAP quantitatively and qualitatively. Notably, it achieves the state-of-the-art on two large-scale egocentric video datasets.}
      \field{issn}{2374-3468, 2159-5399}
      \field{journaltitle}{Proceedings of the AAAI Conference on Artificial Intelligence}
      \field{month}{4}
      \field{number}{07}
      \field{title}{Symbiotic {Attention} with {Privileged} {Information} for {Egocentric} {Action} {Recognition}}
      \field{volume}{34}
      \field{year}{2020}
      \field{pages}{12249\bibrangedash 12256}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1609/aaai.v34i07.6907
      \endverb
      \verb{file}
      \verb Full Text:/Users/mengze/Zotero/storage/9GFU84CD/Wang et al. - 2020 - Symbiotic Attention with Privileged Information fo.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ojs.aaai.org/index.php/AAAI/article/view/6907
      \endverb
      \verb{url}
      \verb https://ojs.aaai.org/index.php/AAAI/article/view/6907
      \endverb
    \endentry
    \entry{huang_ego-vision_2020}{article}{}
      \name{author}{3}{}{%
        {{hash=a674a5619fc006f5693d644d35613257}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yifei},
           giveni={Y\bibinitperiod}}}%
        {{hash=f5812c2f5a852b890572af702630b317}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Minjie},
           giveni={M\bibinitperiod}}}%
        {{hash=e292ab2afea048f7ad6399d6b3301f67}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Yoichi},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{671cc73eec0e808b0406282711a07b84}
      \strng{fullhash}{080d1988e0731cb4097d769505aae495}
      \strng{bibnamehash}{080d1988e0731cb4097d769505aae495}
      \strng{authorbibnamehash}{080d1988e0731cb4097d769505aae495}
      \strng{authornamehash}{671cc73eec0e808b0406282711a07b84}
      \strng{authorfullhash}{080d1988e0731cb4097d769505aae495}
      \field{extraname}{3}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2168-2291, 2168-2305}
      \field{journaltitle}{IEEE Transactions on Human-Machine Systems}
      \field{month}{8}
      \field{number}{4}
      \field{title}{An {Ego}-{Vision} {System} for {Discovering} {Human} {Joint} {Attention}}
      \field{volume}{50}
      \field{year}{2020}
      \field{pages}{306\bibrangedash 316}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/THMS.2020.2965429
      \endverb
      \verb{file}
      \verb An_Ego-Vision_System_for_Discovering_Human_Joint_Attention.pdf:/Users/mengze/Documents/文稿 - Mengze的MacBook Pro/paper/An_Ego-Vision_System_for_Discovering_Human_Joint_Attention.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9057439/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9057439/
      \endverb
    \endentry
    \entry{vaswani_attention_2023}{misc}{}
      \name{author}{8}{}{%
        {{hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod}}}%
        {{hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod}}}%
        {{hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod}}}%
        {{hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N.},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=f2bc899b1160163417da7bf510f15d33}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Lukasz},
           giveni={L\bibinitperiod}}}%
        {{hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{bibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authorbibnamehash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{f82970bbd2bdd7a002d2af62b743d5cc}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.}
      \field{month}{8}
      \field{note}{arXiv:1706.03762 [cs]}
      \field{title}{Attention {Is} {All} {You} {Need}}
      \field{year}{2023}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/H8JYYZNA/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/73P9HBQI/1706.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.03762
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.03762
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Computation and Language}
    \endentry
    \entry{wang_Non-local_2017}{article}{}
      \name{author}{4}{}{%
        {{hash=84a57ab121539e94069a33b4d40492c1}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xiaolong},
           giveni={X\bibinitperiod}}}%
        {{hash=c2c60ceb4a241891e128295a5ae80aef}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross\bibnamedelima B.},
           giveni={R\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=83dd9d464c9f0ea982254939a7f021d8}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhinav},
           giveni={A\bibinitperiod}}}%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{f6d3f9621ed5e17f4801a833099443d2}
      \strng{fullhash}{8d19183dea8b24df6db1b09b8e398adb}
      \strng{bibnamehash}{8d19183dea8b24df6db1b09b8e398adb}
      \strng{authorbibnamehash}{8d19183dea8b24df6db1b09b8e398adb}
      \strng{authornamehash}{f6d3f9621ed5e17f4801a833099443d2}
      \strng{authorfullhash}{8d19183dea8b24df6db1b09b8e398adb}
      \field{extraname}{3}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{CoRR}
      \field{title}{Non-local Neural Networks}
      \field{volume}{abs/1711.07971}
      \field{year}{2017}
      \verb{eprint}
      \verb 1711.07971
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1711.07971
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1711.07971
      \endverb
    \endentry
    \entry{carion_End-to-End_2020}{article}{}
      \name{author}{6}{}{%
        {{hash=0cb223da593b5653feac6f6eabcbe82d}{%
           family={Carion},
           familyi={C\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=e5dfae4582081d649e3a0d5342050016}{%
           family={Massa},
           familyi={M\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod}}}%
        {{hash=a345e20a460089c920bb74098ed450db}{%
           family={Synnaeve},
           familyi={S\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod}}}%
        {{hash=26e026be6d5366fce878100ba03d68c1}{%
           family={Usunier},
           familyi={U\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=28c5859f568975f174c8668976ed369d}{%
           family={Kirillov},
           familyi={K\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=23bcbde34947ed4fd04cc55ff956c83e}{%
           family={Zagoruyko},
           familyi={Z\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{4963c2a11ef1b07108a62832acac80e9}
      \strng{fullhash}{53851df57e601a457251e3876b7dab6a}
      \strng{bibnamehash}{53851df57e601a457251e3876b7dab6a}
      \strng{authorbibnamehash}{53851df57e601a457251e3876b7dab6a}
      \strng{authornamehash}{4963c2a11ef1b07108a62832acac80e9}
      \strng{authorfullhash}{53851df57e601a457251e3876b7dab6a}
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{CoRR}
      \field{title}{End-to-End Object Detection with Transformers}
      \field{volume}{abs/2005.12872}
      \field{year}{2020}
      \verb{eprint}
      \verb 2005.12872
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/abs/2005.12872
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2005.12872
      \endverb
    \endentry
    \entry{neimark_video_2021}{misc}{}
      \name{author}{4}{}{%
        {{hash=8fa0423a697d79ffc606db6a46415a08}{%
           family={Neimark},
           familyi={N\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=164c0280aab2c3dd144d9e6f9db7a7bf}{%
           family={Bar},
           familyi={B\bibinitperiod},
           given={Omri},
           giveni={O\bibinitperiod}}}%
        {{hash=6b2211b59a5c29b2dab32c426d794d46}{%
           family={Zohar},
           familyi={Z\bibinitperiod},
           given={Maya},
           giveni={M\bibinitperiod}}}%
        {{hash=c648468c4f88573480f8c0edb98af6bb}{%
           family={Asselmann},
           familyi={A\bibinitperiod},
           given={Dotan},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{6443ccbe903d38908779fa980aa6822a}
      \strng{fullhash}{1201eba7fd38ff17793ca7773b910aec}
      \strng{bibnamehash}{1201eba7fd38ff17793ca7773b910aec}
      \strng{authorbibnamehash}{1201eba7fd38ff17793ca7773b910aec}
      \strng{authornamehash}{6443ccbe903d38908779fa980aa6822a}
      \strng{authorfullhash}{1201eba7fd38ff17793ca7773b910aec}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents VTN, a transformer-based framework for video recognition. Inspired by recent developments in vision transformers, we ditch the standard approach in video action recognition that relies on 3D ConvNets and introduce a method that classifies actions by attending to the entire video sequence information. Our approach is generic and builds on top of any given 2D spatial network. In terms of wall runtime, it trains \$16.1{\textbackslash}times\$ faster and runs \$5.1{\textbackslash}times\$ faster during inference while maintaining competitive accuracy compared to other state-of-the-art methods. It enables whole video analysis, via a single end-to-end pass, while requiring \$1.5{\textbackslash}times\$ fewer GFLOPs. We report competitive results on Kinetics-400 and present an ablation study of VTN properties and the trade-off between accuracy and inference speed. We hope our approach will serve as a new baseline and start a fresh line of research in the video recognition domain. Code and models are available at: https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md}
      \field{month}{8}
      \field{note}{arXiv:2102.00719 [cs]}
      \field{title}{Video {Transformer} {Network}}
      \field{year}{2021}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/CZ7AELIB/Neimark et al. - 2021 - Video Transformer Network.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/YEBXXGGL/2102.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2102.00719
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2102.00719
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{russakovsky_imagenet_2015}{misc}{}
      \name{author}{12}{}{%
        {{hash=2a74ec28b731b015747e2af5f0b519e1}{%
           family={Russakovsky},
           familyi={R\bibinitperiod},
           given={Olga},
           giveni={O\bibinitperiod}}}%
        {{hash=0ae7fdc13773f928525f673b05f37149}{%
           family={Deng},
           familyi={D\bibinitperiod},
           given={Jia},
           giveni={J\bibinitperiod}}}%
        {{hash=18c26ddba8b9dd77f278213fd4e93ce4}{%
           family={Su},
           familyi={S\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=bdb3759bbe6ab0618874848557abd459}{%
           family={Krause},
           familyi={K\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=434c8ee62c507c93be09958bae942da5}{%
           family={Satheesh},
           familyi={S\bibinitperiod},
           given={Sanjeev},
           giveni={S\bibinitperiod}}}%
        {{hash=e3f8564120f7528479a3ea1b507bd705}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Sean},
           giveni={S\bibinitperiod}}}%
        {{hash=6e8d947dd72de23b8500095b595e1e99}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Zhiheng},
           giveni={Z\bibinitperiod}}}%
        {{hash=e91a4c2044bccdbef249eabc886ff988}{%
           family={Karpathy},
           familyi={K\bibinitperiod},
           given={Andrej},
           giveni={A\bibinitperiod}}}%
        {{hash=c8d6add84efe17681e0d4968ebf47fdc}{%
           family={Khosla},
           familyi={K\bibinitperiod},
           given={Aditya},
           giveni={A\bibinitperiod}}}%
        {{hash=9c5821708eb9cc9bc6c92c66ada53892}{%
           family={Bernstein},
           familyi={B\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=963e9b2526a7150c418b4e9e9d19a82f}{%
           family={Berg},
           familyi={B\bibinitperiod},
           given={Alexander\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=cd00ce5bc45f687c432e52e0fa1a7aa6}{%
           family={Fei-Fei},
           familyi={F\bibinithyphendelim F\bibinitperiod},
           given={Li},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{8ba3ccfdb2fef3e42589e7ae3b2c964a}
      \strng{fullhash}{59755200ef94ffc1362c28c17d315fe0}
      \strng{bibnamehash}{59755200ef94ffc1362c28c17d315fe0}
      \strng{authorbibnamehash}{59755200ef94ffc1362c28c17d315fe0}
      \strng{authornamehash}{8ba3ccfdb2fef3e42589e7ae3b2c964a}
      \strng{authorfullhash}{59755200ef94ffc1362c28c17d315fe0}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.}
      \field{month}{1}
      \field{note}{arXiv:1409.0575 [cs]}
      \field{title}{{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}}
      \field{year}{2015}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/HQNP5B5V/Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/X6QMNLY5/1409.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1409.0575
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1409.0575
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,I.4.8,I.5.2}
    \endentry
    \entry{kay_kinetics_2017}{misc}{}
      \name{author}{12}{}{%
        {{hash=b8078c432e84a97193dab9fe1c314c4f}{%
           family={Kay},
           familyi={K\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod}}}%
        {{hash=9769c01477fd6a34e0f7732729ee8eb4}{%
           family={Carreira},
           familyi={C\bibinitperiod},
           given={Joao},
           giveni={J\bibinitperiod}}}%
        {{hash=9d16b7284df92c9adaee86c37ab992df}{%
           family={Simonyan},
           familyi={S\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod}}}%
        {{hash=a2182f47f4763230d56f9703af321eca}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=1947a8ad779b49767f659c94bdc2bd20}{%
           family={Hillier},
           familyi={H\bibinitperiod},
           given={Chloe},
           giveni={C\bibinitperiod}}}%
        {{hash=db9130ac2a312179c30d36279667e12f}{%
           family={Vijayanarasimhan},
           familyi={V\bibinitperiod},
           given={Sudheendra},
           giveni={S\bibinitperiod}}}%
        {{hash=5fe6121db340f7bc1617a2a31cb5e231}{%
           family={Viola},
           familyi={V\bibinitperiod},
           given={Fabio},
           giveni={F\bibinitperiod}}}%
        {{hash=3e0f493c1ce741283206bf1f0d3c12f5}{%
           family={Green},
           familyi={G\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=329e447b0059cd0bc92227b1dd08c81e}{%
           family={Back},
           familyi={B\bibinitperiod},
           given={Trevor},
           giveni={T\bibinitperiod}}}%
        {{hash=48473ae39bb4341970797158e388a161}{%
           family={Natsev},
           familyi={N\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=19778ba911c7467d1742efe0289f2d16}{%
           family={Suleyman},
           familyi={S\bibinitperiod},
           given={Mustafa},
           giveni={M\bibinitperiod}}}%
        {{hash=c72fc39e94030f67717052309266a44d}{%
           family={Zisserman},
           familyi={Z\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{da24e63d7cb3e01ce61e5f8bf47323f1}
      \strng{fullhash}{af960076e90d7e0ef9324f413d43f0a1}
      \strng{bibnamehash}{af960076e90d7e0ef9324f413d43f0a1}
      \strng{authorbibnamehash}{af960076e90d7e0ef9324f413d43f0a1}
      \strng{authornamehash}{da24e63d7cb3e01ce61e5f8bf47323f1}
      \strng{authorfullhash}{af960076e90d7e0ef9324f413d43f0a1}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action. Each clip lasts around 10s and is taken from a different YouTube video. The actions are human focussed and cover a broad range of classes including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands. We describe the statistics of the dataset, how it was collected, and give some baseline performance figures for neural network architectures trained and tested for human action classification on this dataset. We also carry out a preliminary analysis of whether imbalance in the dataset leads to bias in the classifiers.}
      \field{month}{5}
      \field{note}{arXiv:1705.06950 [cs]}
      \field{title}{The {Kinetics} {Human} {Action} {Video} {Dataset}}
      \field{year}{2017}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/Z4EN24B3/Kay et al. - 2017 - The Kinetics Human Action Video Dataset.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/CM3S6TD5/1705.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1705.06950
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1705.06950
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{Sun_Rev_2017}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=7437556e576c6f4e2ade58a9aa980ec5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Chen},
           giveni={C\bibinitperiod}}}%
        {{hash=7244177886497a3743e18fc63c2efcad}{%
           family={Shrivastava},
           familyi={S\bibinitperiod},
           given={Abhinav},
           giveni={A\bibinitperiod}}}%
        {{hash=72046c7dbd4a54893754d1a062d4533d}{%
           family={Singh},
           familyi={S\bibinitperiod},
           given={Saurabh},
           giveni={S\bibinitperiod}}}%
        {{hash=83dd9d464c9f0ea982254939a7f021d8}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhinav},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{8da9d8303d53405bd5903d766902199f}
      \strng{fullhash}{6d71337b252c9662ace0d05e723d7d78}
      \strng{bibnamehash}{6d71337b252c9662ace0d05e723d7d78}
      \strng{authorbibnamehash}{6d71337b252c9662ace0d05e723d7d78}
      \strng{authornamehash}{8da9d8303d53405bd5903d766902199f}
      \strng{authorfullhash}{6d71337b252c9662ace0d05e723d7d78}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2017 IEEE International Conference on Computer Vision (ICCV)}
      \field{title}{Revisiting Unreasonable Effectiveness of Data in Deep Learning Era}
      \field{year}{2017}
      \field{pages}{843\bibrangedash 852}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICCV.2017.97
      \endverb
    \endentry
    \entry{ferrari_compositional_2018}{incollection}{}
      \name{author}{3}{}{%
        {{hash=921060267e2232002b24174e3525b432}{%
           family={Kato},
           familyi={K\bibinitperiod},
           given={Keizo},
           giveni={K\bibinitperiod}}}%
        {{hash=07e26844b73cfbeb7f20e73779d321e4}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yin},
           giveni={Y\bibinitperiod}}}%
        {{hash=83dd9d464c9f0ea982254939a7f021d8}{%
           family={Gupta},
           familyi={G\bibinitperiod},
           given={Abhinav},
           giveni={A\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=2d9b2bb140830bf8f7f642c17692a8e4}{%
           family={Ferrari},
           familyi={F\bibinitperiod},
           given={Vittorio},
           giveni={V\bibinitperiod}}}%
        {{hash=c4c76fca369ecb436d9729820e745123}{%
           family={Hebert},
           familyi={H\bibinitperiod},
           given={Martial},
           giveni={M\bibinitperiod}}}%
        {{hash=bd7af1e31d4938e27dbc867b4bb71e9d}{%
           family={Sminchisescu},
           familyi={S\bibinitperiod},
           given={Cristian},
           giveni={C\bibinitperiod}}}%
        {{hash=214a71ab353c5570ed4acb95cf84f539}{%
           family={Weiss},
           familyi={W\bibinitperiod},
           given={Yair},
           giveni={Y\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{b6572c114455b988cf07c54927be33bb}
      \strng{fullhash}{6b754ca822e2022f2c629ef75fa94690}
      \strng{bibnamehash}{6b754ca822e2022f2c629ef75fa94690}
      \strng{authorbibnamehash}{6b754ca822e2022f2c629ef75fa94690}
      \strng{authornamehash}{b6572c114455b988cf07c54927be33bb}
      \strng{authorfullhash}{6b754ca822e2022f2c629ef75fa94690}
      \strng{editorbibnamehash}{0d71006df560b3f7aa8fdb55efa8491f}
      \strng{editornamehash}{55075d71201f5d17a91f0ae9d748d278}
      \strng{editorfullhash}{0d71006df560b3f7aa8fdb55efa8491f}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The world of human-object interactions is rich. While generally we sit on chairs and sofas, if need be we can even sit on TVs or top of shelves. In recent years, there has been progress in modeling actions and human-object interactions. However, most of these approaches require lots of data. It is not clear if the learned representations of actions are generalizable to new categories. In this paper, we explore the problem of zero-shot learning of human-object interactions. Given limited verb-noun interactions in training data, we want to learn a model than can work even on unseen combinations. To deal with this problem, In this paper, we propose a novel method using external knowledge graph and graph convolutional networks which learns how to compose classiﬁers for verbnoun pairs. We also provide benchmarks on several dataset for zero-shot learning including both image and video. We hope our method, dataset and baselines will facilitate future research in this direction.}
      \field{booktitle}{Computer {Vision} – {ECCV} 2018}
      \field{isbn}{978-3-030-01263-2 978-3-030-01264-9}
      \field{note}{Series Title: Lecture Notes in Computer Science}
      \field{title}{Compositional {Learning} for {Human} {Object} {Interaction}}
      \field{volume}{11218}
      \field{year}{2018}
      \field{pages}{247\bibrangedash 264}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1007/978-3-030-01264-9_15
      \endverb
      \verb{file}
      \verb Kato et al. - 2018 - Compositional Learning for Human Object Interactio.pdf:/Users/mengze/Zotero/storage/VSKNA9K2/Kato et al. - 2018 - Compositional Learning for Human Object Interactio.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-030-01264-9_15
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-030-01264-9_15
      \endverb
    \endentry
    \entry{baradel_object_2018}{misc}{}
      \name{author}{5}{}{%
        {{hash=dad2a271a3f72fa05bc18a0605c38b67}{%
           family={Baradel},
           familyi={B\bibinitperiod},
           given={Fabien},
           giveni={F\bibinitperiod}}}%
        {{hash=6ff34c28edc9dbeffd3f6181c331596a}{%
           family={Neverova},
           familyi={N\bibinitperiod},
           given={Natalia},
           giveni={N\bibinitperiod}}}%
        {{hash=59015f0f88a7f676bfe9dc39b43c7814}{%
           family={Wolf},
           familyi={W\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=063da46d5fe07990812f2a72766d531a}{%
           family={Mille},
           familyi={M\bibinitperiod},
           given={Julien},
           giveni={J\bibinitperiod}}}%
        {{hash=666c12517626c817b8d3a1ba792fc2c2}{%
           family={Mori},
           familyi={M\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{64b020cc6ce113f6606d76b63e946064}
      \strng{fullhash}{99644925c80addbd65aae7a502f336f7}
      \strng{bibnamehash}{99644925c80addbd65aae7a502f336f7}
      \strng{authorbibnamehash}{99644925c80addbd65aae7a502f336f7}
      \strng{authornamehash}{64b020cc6ce113f6606d76b63e946064}
      \strng{authorfullhash}{99644925c80addbd65aae7a502f336f7}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Human activity recognition is typically addressed by detecting key concepts like global and local motion, features related to object classes present in the scene, as well as features related to the global context. The next open challenges in activity recognition require a level of understanding that pushes beyond this and call for models with capabilities for fine distinction and detailed comprehension of interactions between actors and objects in a scene. We propose a model capable of learning to reason about semantically meaningful spatiotemporal interactions in videos. The key to our approach is a choice of performing this reasoning at the object level through the integration of state of the art object detection networks. This allows the model to learn detailed spatial interactions that exist at a semantic, object-interaction relevant level. We evaluate our method on three standard datasets (Twenty-BN Something-Something, VLOG and EPIC Kitchens) and achieve state of the art results on all of them. Finally, we show visualizations of the interactions learned by the model, which illustrate object classes and their interactions corresponding to different activity classes.}
      \field{month}{9}
      \field{note}{arXiv:1806.06157 [cs]}
      \field{title}{Object {Level} {Visual} {Reasoning} in {Videos}}
      \field{year}{2018}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/M2PFHNDL/Baradel et al. - 2018 - Object Level Visual Reasoning in Videos.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/TZI3TG4L/1806.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1806.06157
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1806.06157
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{xu_learning_2019}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=e60e0459443fb217dad2d5aae6d3f6ec}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Bingjie},
           giveni={B\bibinitperiod}}}%
        {{hash=15630640de070b49c2f9909446a2284f}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Yongkang},
           giveni={Y\bibinitperiod}}}%
        {{hash=1c6e653d1c884531f9bc28d48227c534}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Junnan},
           giveni={J\bibinitperiod}}}%
        {{hash=fb2121ec50debb9bbe4e9bc0625fd719}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Qi},
           giveni={Q\bibinitperiod}}}%
        {{hash=81c8f5b68b7e273774f22ad9361ae0b8}{%
           family={Kankanhalli},
           familyi={K\bibinitperiod},
           given={Mohan\bibnamedelima S.},
           giveni={M\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Long Beach, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{62b063810b07e6529e298d8ab46da9cb}
      \strng{fullhash}{e5abaefec36125d482d98809f05285b5}
      \strng{bibnamehash}{e5abaefec36125d482d98809f05285b5}
      \strng{authorbibnamehash}{e5abaefec36125d482d98809f05285b5}
      \strng{authornamehash}{62b063810b07e6529e298d8ab46da9cb}
      \strng{authorfullhash}{e5abaefec36125d482d98809f05285b5}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The recent advances in instance-level detection tasks lay a strong foundation for automated visual scenes understanding. However, the ability to fully comprehend a social scene still eludes us. In this work, we focus on detecting human-object interactions (HOIs) in images, an essential step towards deeper scene understanding. HOI detection aims to localize human and objects, as well as to identify the complex interactions between them. Innate in practical problems with large label space, HOI categories exhibit a long-tail distribution, i.e., there exist some rare categories with very few training samples. Given the key observation that HOIs contain intrinsic semantic regularities despite they are visually diverse, we tackle the challenge of longtail HOI categories by modeling the underlying regularities among verbs and objects in HOIs as well as general relationships. In particular, we construct a knowledge graph based on the ground-truth annotations of training dataset and external source. In contrast to direct knowledge incorporation, we address the necessity of dynamic imagespeciﬁc knowledge retrieval by multi-modal learning, which leads to an enhanced semantic embedding space for HOI comprehension. The proposed method shows improved performance on V-COCO and HICO-DET benchmarks, especially when predicting the rare HOI categories.}
      \field{booktitle}{2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{isbn}{978-1-72813-293-8}
      \field{month}{6}
      \field{title}{Learning to {Detect} {Human}-{Object} {Interactions} {With} {Knowledge}}
      \field{year}{2019}
      \field{pages}{2019\bibrangedash 2028}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/CVPR.2019.00212
      \endverb
      \verb{file}
      \verb Xu et al. - 2019 - Learning to Detect Human-Object Interactions With .pdf:/Users/mengze/Zotero/storage/SDIEUARV/Xu et al. - 2019 - Learning to Detect Human-Object Interactions With .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8953301/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8953301/
      \endverb
    \endentry
    \entry{shvetsova_everything_2022}{inproceedings}{}
      \name{author}{9}{}{%
        {{hash=2b694546dfb1d5798a0297303b9eefac}{%
           family={Shvetsova},
           familyi={S\bibinitperiod},
           given={Nina},
           giveni={N\bibinitperiod}}}%
        {{hash=948ce605b73693cf329c7ad15180ae9a}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=4061fbecb11a224923e0caad26faf56d}{%
           family={Rouditchenko},
           familyi={R\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=0a327007a0b097a2d8bfa1b4eb2086d1}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod}}}%
        {{hash=8f101126b3acf3a5a0f51d86f0fe89b8}{%
           family={Kingsbury},
           familyi={K\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=b28550979e1f46d5c67bcd9212bab845}{%
           family={Feris},
           familyi={F\bibinitperiod},
           given={Rogerio},
           giveni={R\bibinitperiod}}}%
        {{hash=0bd189af57105df4f4e2d749c815bf13}{%
           family={Harwath},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=079738ec97fefceec5036d7c3657c667}{%
           family={Glass},
           familyi={G\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=abbb2b3478036776ebfd1dec522c0091}{%
           family={Kuehne},
           familyi={K\bibinitperiod},
           given={Hilde},
           giveni={H\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {New Orleans, LA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{80a2e909cf72b34ebb0058b6499f31e5}
      \strng{fullhash}{4e064df7e19337cf0d8bb0fbe9268e4c}
      \strng{bibnamehash}{4e064df7e19337cf0d8bb0fbe9268e4c}
      \strng{authorbibnamehash}{4e064df7e19337cf0d8bb0fbe9268e4c}
      \strng{authornamehash}{80a2e909cf72b34ebb0058b6499f31e5}
      \strng{authorfullhash}{4e064df7e19337cf0d8bb0fbe9268e4c}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})}
      \field{isbn}{978-1-66546-946-3}
      \field{month}{6}
      \field{title}{Everything at {Once} – {Multi}-modal {Fusion} {Transformer} for {Video} {Retrieval}}
      \field{year}{2022}
      \field{pages}{19988\bibrangedash 19997}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/CVPR52688.2022.01939
      \endverb
      \verb{file}
      \verb Shvetsova et al. - 2022 - Everything at Once – Multi-modal Fusion Transforme.pdf:/Users/mengze/Zotero/storage/Q2TBJQLX/Shvetsova et al. - 2022 - Everything at Once – Multi-modal Fusion Transforme.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9879495/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9879495/
      \endverb
    \endentry
    \entry{ren_faster_2016}{misc}{}
      \name{author}{4}{}{%
        {{hash=bb295293acacd54387339079ebbe4ead}{%
           family={Ren},
           familyi={R\bibinitperiod},
           given={Shaoqing},
           giveni={S\bibinitperiod}}}%
        {{hash=6b4b60e909e78633945f3f9c9dc83e01}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Kaiming},
           giveni={K\bibinitperiod}}}%
        {{hash=bd5dadbe57bedc5957c19a3154c4d424}{%
           family={Girshick},
           familyi={G\bibinitperiod},
           given={Ross},
           giveni={R\bibinitperiod}}}%
        {{hash=f85751488058842b5777c7b4074077b5}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Jian},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{f086ca4da3e532e8a41cb758ea461825}
      \strng{fullhash}{008a132af3e2d4ff15eb01a8fb4b005c}
      \strng{bibnamehash}{008a132af3e2d4ff15eb01a8fb4b005c}
      \strng{authorbibnamehash}{008a132af3e2d4ff15eb01a8fb4b005c}
      \strng{authornamehash}{f086ca4da3e532e8a41cb758ea461825}
      \strng{authorfullhash}{008a132af3e2d4ff15eb01a8fb4b005c}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{month}{1}
      \field{note}{arXiv:1506.01497 [cs]}
      \field{shorttitle}{Faster {R}-{CNN}}
      \field{title}{Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}}
      \field{urlday}{2}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{urldateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/SU6I87NM/Ren et al. - 2016 - Faster R-CNN Towards Real-Time Object Detection w.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/JP7ERQ9A/1506.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1506.01497
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1506.01497
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{Damen2018EPICKITCHENS}{inproceedings}{}
      \name{author}{11}{}{%
        {{hash=712adc8e0e74b98a58fbf432290180d2}{%
           family={Damen},
           familyi={D\bibinitperiod},
           given={Dima},
           giveni={D\bibinitperiod}}}%
        {{hash=8a5f944371f0edd69817b054cf2fabea}{%
           family={Doughty},
           familyi={D\bibinitperiod},
           given={Hazel},
           giveni={H\bibinitperiod}}}%
        {{hash=a79bf15b29522f05fc8a35b7bab3bc47}{%
           family={Farinella},
           familyi={F\bibinitperiod},
           given={Giovanni\bibnamedelima Maria},
           giveni={G\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=132467c4a712be4725c988c89c68a30e}{%
           family={Fidler},
           familyi={F\bibinitperiod},
           given={Sanja},
           giveni={S\bibinitperiod}}}%
        {{hash=01ee2926b820b5688c1319ef75c3ee21}{%
           family={Furnari},
           familyi={F\bibinitperiod},
           given={Antonino},
           giveni={A\bibinitperiod}}}%
        {{hash=bd37d9c6d44a591d8b2882df82147ffe}{%
           family={Kazakos},
           familyi={K\bibinitperiod},
           given={Evangelos},
           giveni={E\bibinitperiod}}}%
        {{hash=6ccb227c9c28ae7723c60eecb7bcb3e2}{%
           family={Moltisanti},
           familyi={M\bibinitperiod},
           given={Davide},
           giveni={D\bibinitperiod}}}%
        {{hash=3cf5b038eab6d058826fe8933fcdc191}{%
           family={Munro},
           familyi={M\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=4a69412f6803494dcdfd4b4c60733a0c}{%
           family={Perrett},
           familyi={P\bibinitperiod},
           given={Toby},
           giveni={T\bibinitperiod}}}%
        {{hash=4f32e69ba9b4bb917b4843f7045e0dff}{%
           family={Price},
           familyi={P\bibinitperiod},
           given={Will},
           giveni={W\bibinitperiod}}}%
        {{hash=98eea0df034e53378a945ed4a8d14b99}{%
           family={Wray},
           familyi={W\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{2c5dace588eb8a2c5327df30ed07e18d}
      \strng{fullhash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{bibnamehash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{authorbibnamehash}{b3fb6f48a4bdc248122aef488d863382}
      \strng{authornamehash}{2c5dace588eb8a2c5327df30ed07e18d}
      \strng{authorfullhash}{b3fb6f48a4bdc248122aef488d863382}
      \field{extraname}{2}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{European Conference on Computer Vision (ECCV)}
      \field{title}{Scaling Egocentric Vision: The EPIC-KITCHENS Dataset}
      \field{year}{2018}
    \endentry
    \entry{loshchilov_decoupled_2019}{misc}{}
      \name{author}{2}{}{%
        {{hash=1241b8181104f1917578d4c7f9b323b6}{%
           family={Loshchilov},
           familyi={L\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=528d4af87fd2ecf5fb8a22db913ce088}{%
           family={Hutter},
           familyi={H\bibinitperiod},
           given={Frank},
           giveni={F\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{fullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{bibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorbibnamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authornamehash}{b308ccb07134a06ec3735828ac4f15e2}
      \strng{authorfullhash}{b308ccb07134a06ec3735828ac4f15e2}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{month}{1}
      \field{note}{arXiv:1711.05101 [cs, math]}
      \field{title}{Decoupled {Weight} {Decay} {Regularization}}
      \field{urlday}{26}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/mengze/Zotero/storage/4YD99QNU/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/Users/mengze/Zotero/storage/2TT9ITEF/1711.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1711.05101
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1711.05101
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control}
    \endentry
  \enddatalist
\endrefsection
\endinput

