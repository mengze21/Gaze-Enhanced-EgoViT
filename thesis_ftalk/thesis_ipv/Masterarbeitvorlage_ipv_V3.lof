\babel@toc {american}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces A chronological overview of representative work in video action recognition before 2020 \blx@tocontentsinit {0}\cite {zhu2020comprehensive}.}}{8}{figure.caption.3}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces The structure of \acrfull {tsn} \blx@tocontentsinit {0}\cite {zhu2020comprehensive}}}{8}{figure.caption.4}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces The schema of Scaled Dot-Product Attention (a) \blx@tocontentsinit {0}\cite {vaswani_attention_2023} and Multi-Head Attention (b) \blx@tocontentsinit {0}\cite {vaswani_attention_2023}}}{10}{figure.caption.5}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Scaled Dot-Product Attention}}}{10}{figure.caption.5}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Multi-Head Attention}}}{10}{figure.caption.5}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces The structure of transformer \blx@tocontentsinit {0}\cite {vaswani_attention_2023}.}}{11}{figure.caption.6}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces The architecture of Video Swin Transformer (Swin-T version) \blx@tocontentsinit {0}\cite {liu_video_2021}.}}{14}{figure.caption.7}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces The structure of Video Swin Transformer Block \blx@tocontentsinit {0}\cite {liu_video_2021}.}}{14}{figure.caption.8}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces The mechanism of 3D shifted windows \blx@tocontentsinit {0}\cite {liu_video_2021}.}}{15}{figure.caption.9}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces The architecture of EgoViT with Dynamic Class Token Generator\blx@tocontentsinit {0}\cite {pan_egovit_2023}.}}{15}{figure.caption.10}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Overall architecture of the Gaze-Enhanced EgoViT.}}{18}{figure.caption.11}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces The data pipeline of the Gaze-Enhanced DCTG module.}}{20}{figure.caption.12}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The structure of the Gaze Feature Networks.}}{21}{figure.caption.13}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces The structure and the data pipeline of the short-term stage.}}{24}{figure.caption.14}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces The structure the data pipeline of long-term stage.}}{25}{figure.caption.15}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces The structure of the Dynamic Merging module.}}{26}{figure.caption.16}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The training loss and accuracy curves for the original EgoViT model trained without pretrained weights. The model is trained over 40 epochs with a learning rate of 1e-5. Blue curve: training accuracy, red curve: training loss.}}{32}{figure.caption.18}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces The training loss and accuracy curves for the original EgoViT model trained with pretrained weights. The model is trained over 20 epochs with a learning rate of 1e-5. Blue curve: training accuracy, red curve: training loss.}}{33}{figure.caption.19}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces The training loss and accuracy curves for the original EgoViT model trained with pretrained weights. The model is trained over 30 epochs with a scheduler learning rate. Blue curve: training accuracy, red curve: training loss.}}{34}{figure.caption.20}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Training loss and accuracy of the enhanced EgoViT with gaze-hand-object features. Blue curve: training accuracy, red curve: training loss.}}{37}{figure.caption.23}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Training loss and accuracy of the enhanced EgoViT with gaze features. Blue curve: training accuracy, red curve: training loss.}}{37}{figure.caption.24}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces The class-wise total count (blue bars) and accuracy (red line) of the enhanced EgoViT model. The x-axis represents the different classes, while the left y-axis shows the total count of instances per class, and the right y-axis shows the accuracy for each class. }}{38}{figure.caption.25}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Training loss and accuracy of the enhanced EgoViT version 2 with gaze-hand-object features. Blue curve: training accuracy, red curve: training loss.}}{40}{figure.caption.27}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Training loss and accuracy of the original EgoViT version 3 with hand-object features. Blue curve: training accuracy, red curve: training loss.}}{41}{figure.caption.29}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Training loss and accuracy of the enhanced EgoViT version 3 with gaze-hand-object features. Blue curve: training accuracy, red curve: training loss.}}{42}{figure.caption.30}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Training loss and accuracy of the enhanced EgoViT version 3 with gaze features. Blue curve: training accuracy, red curve: training loss.}}{42}{figure.caption.31}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Comparison of training loss of the variants of enhanced EgoViT with gaze-hand-object features.}}{43}{figure.caption.32}%
\addvspace {10\p@ }
